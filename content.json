{"meta":{"title":"程序员Yz","subtitle":null,"description":null,"author":"Colin Ye","url":"http://zhuangyea.github.io"},"pages":[{"title":"About","date":"2017-10-03T02:48:33.000Z","updated":"2019-11-12T02:00:56.562Z","comments":true,"path":"about/index.html","permalink":"http://zhuangyea.github.io/about/index.html","excerpt":"","text":"一句话 Just do it ! (翻译：我只是个搞 IT的！哭笑脸) 关于我 一个莫名其妙的，喜欢敲代码，喜欢研究技术的，表面上高冷、不苟言笑的， 偶尔又嬉皮笑脸，偶尔又特立独行的，双重性格的技术爱好者！ 联系我 Email: yyeezz@163.com微信:"},{"title":"文章分类","date":"2020-07-14T02:49:09.612Z","updated":"2019-04-29T06:22:05.559Z","comments":false,"path":"categories/index.html","permalink":"http://zhuangyea.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-07-14T02:49:09.602Z","updated":"2018-12-26T01:54:10.030Z","comments":false,"path":"tags/index.html","permalink":"http://zhuangyea.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"使用docker-compose搭建Prometheus+Grafana监控系统性能","slug":"docker/使用docker-compose搭建Prometheus+Grafana监控系统性能","date":"2020-08-13T11:50:00.000Z","updated":"2020-08-18T10:51:53.964Z","comments":true,"path":"2020/08/13/docker/使用docker-compose搭建Prometheus+Grafana监控系统性能/","link":"","permalink":"http://zhuangyea.github.io/2020/08/13/docker/使用docker-compose搭建Prometheus+Grafana监控系统性能/","excerpt":"","text":"概念与设计总览 Prometheus 是一个开源的服务监控系统和时间序列数据库 Grafana是开源的可视化和分析软件 一、环境说明 Linux Centos7 docker-compose 二、安装node_exporter（选装，注意prometheus.yml配置） node_exporter用于采集系统信息，github地址 前往https://github.com/prometheus/node_exporter/releases列表下载对应系统的最新文件 解压 启动：./node_exporter –web.listen-address=”:9100” &amp; 打开页面：http://localhost:9100 三、安装mysql_exporter（选装，注意prometheus.yml配置） mysql_exporter用于采集Mysql信息，github地址 前往https://github.com/prometheus/mysqld_exporter/releases列表下载对应系统的最新文件 解压。参考第二步图片 启动。[为选填参数] 12export DATA_SOURCE_NAME='root:yourpass@(127.0.0.1:30009)/[dbname]';./mysqld_exporter-0.12.1.linux-amd64/mysqld_exporter --web.listen-address=0.0.0.0:30008 --config.my-cnf /opt/software/docker/mysql5.7/mysql/my.cnf 打开页面 http://localhost:30008 四、docker-compose安装Prometheus 编写docker-compose.yml 12345678910111213version: '3.3'services: prometheus: image: prom/prometheus:latest container_name: prometheus restart: always privileged: true user: root ports: - 9090:9090 volumes: #将刚刚准备好的defaults.ini直接映射到/usr/share/grafana/conf/defaults.ini路径 - ./prometheus.yml:/etc/prometheus/prometheus.yml 新建prometheus.yml并配置node exporter监控数据 12345678910111213141516171819202122232425262728293031323334353637# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\"# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['docker.for.mac.host.internal:9090'] # 服务器上使用内网ip # 采集node exporter监控数据 - job_name: 'node' static_configs: - targets: ['docker.for.mac.localhost:9100'] # 服务器上使用内网ip # 采集mysql exporter监控数据 - job_name: 'mysql' static_configs: - targets: ['docker.for.mac.localhost:30008'] # 服务器上使用内网ip 启动docker 启动容器：docker-compose up -d 查看容器：docker-compose ps 删除容器：docker-compose rm 验证并查看node_exporter状态 prometheus浏览器中输入：http://localhost:9090 五、docker-compose安装Grafana 编写docker-compose.yml 1234567891011121314151617181920212223242526272829version: '3.3'services: grafana: image: grafana/grafana:latest container_name: grafana restart: always privileged: true user: root ports: - 3000:3000 environment: - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource volumes: #将刚刚准备好的defaults.ini直接映射到/usr/share/grafana/conf/defaults.ini路径 - ./config/defaults.ini:/usr/share/grafana/conf/defaults.ini #data目录，如果使用了默认的sqlite3数据库，则文件会存在这边 - ./data/grafana:/var/lib/grafana #log目录，后期会写入log文件 - ./log:/var/log/grafana # 添加插件 *注意修改defaults.ini文件：server_url = http://renderer:8081/render# renderer:# image: grafana/grafana-image-renderer# restart: always# ports:# - 8081:8081# container_name: renderer# environment:# - GF_RENDERER_PLUGIN_TZ=Asia/Shanghai# - GF_RENDERER_PLUGIN_IGNORE_HTTPS_ERRORS=true 启动docker 启动容器：docker-compose up -d 查看容器：docker-compose ps 删除容器：docker-compose rm 验证，默认用户名密码为admin/admin grafana浏览器中输入：http://localhost:3000 新增prometheus数据源并配置服务地址 寻找别人配置好的模板，其他模板查看https://grafana.com/grafana/dashboards 导入mysql_exporter模板，https://grafana.com/grafana/dashboards/8919 导入mysql_exporter模板，https://grafana.com/grafana/dashboards/7362 导入模板 查看","categories":[{"name":"运维","slug":"运维","permalink":"http://zhuangyea.github.io/categories/运维/"},{"name":"Prometheus","slug":"运维/Prometheus","permalink":"http://zhuangyea.github.io/categories/运维/Prometheus/"},{"name":"Grafana","slug":"运维/Prometheus/Grafana","permalink":"http://zhuangyea.github.io/categories/运维/Prometheus/Grafana/"},{"name":"Docker","slug":"运维/Prometheus/Grafana/Docker","permalink":"http://zhuangyea.github.io/categories/运维/Prometheus/Grafana/Docker/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://zhuangyea.github.io/tags/运维/"},{"name":"Prometheus","slug":"Prometheus","permalink":"http://zhuangyea.github.io/tags/Prometheus/"},{"name":"Grafana","slug":"Grafana","permalink":"http://zhuangyea.github.io/tags/Grafana/"},{"name":"Docker","slug":"Docker","permalink":"http://zhuangyea.github.io/tags/Docker/"}]},{"title":"SkyWalking源码编译及本地调试","slug":"docker/SkyWalking源码编译及调试","date":"2020-08-11T11:22:00.000Z","updated":"2020-08-12T03:23:22.892Z","comments":true,"path":"2020/08/11/docker/SkyWalking源码编译及调试/","link":"","permalink":"http://zhuangyea.github.io/2020/08/11/docker/SkyWalking源码编译及调试/","excerpt":"","text":"概念与设计总览 SkyWalking: 一个开源的可观测平台, 用于从服务和云原生基础设施收集, 分析, 聚合及可视化数据。SkyWalking 提供了一种简便的方式来清晰地观测分布式系统, 甚至横跨多个云平台。SkyWalking 更是一个现代化的应用程序性能监控(Application Performance Monitoring)系统, 尤其专为云原生、基于容器的分布式系统设计 为什么使用SkyWalking：在许多不同的场景下, SkyWalking 为观察和监控分布式系统提供了解决方案。首先是像传统的方式那样, SkyWalking 为服务提供了自动打点的代理, 如 Java, C# , Node.js , Go , PHP 以及 Nginx LUA（包括 Python 和 C++ 调用的 SDK 捐献） 一、环境说明 Linux Centos7 ElasticSearch 7.8.0 SkyWalking 8.0.1 JDK 1.8 Idea 2020.01 二、从 GitHub 构建 预备好 Git, JDK8 以及 Maven3 git clone https://github.com/apache/skywalking.git cd skywalking/ 使用 git checkout [tagname] 切换到指定的 tag (可选的, 只有当你想编译某个特定版本的代码时才需要) git submodule init git submodule update 这步可忽略。下载maven、npm包慢以及Mac权限问题所以我修改了代码 Makefile：增加 –settings=/Users/yezhuang/Documents/software/maven/apache-maven-3.6.0/conf/settings.xml apm-webapp/pom.xml：增加 –registry=https://registry.npm.taobao.org –unsafe-perm –unsafe-perm解决mac权限问题 这步可忽略。要求变更logo图标 skywalking-ui/src/components/rk-header.vue 编译及打包 运行 ./mvnw clean package -DskipTests docker镜像打包：export HUB=skywalking &amp;&amp; export TAG=8.0.1 &amp;&amp; export ES_VERSION=es7 &amp;&amp; export SKIP_TEST=true &amp;&amp; make docker 所有打出来的包都在目录 /dist 下 (Linux 下为 .tar.gz, Windows 下为 .zip) 如果是打docker镜像包，通过docker images查看 三、本地调试 创建测试工程 在同一工程中通过导入 module 方式到 skywalking 导入 skywalking 工程 在联调工程的 JVM 参数中指定 skywalking 编译结果目录 启动工程调试（在需要调试的代码上打断点） 验证，我增加了制定消息头 页面请求 skywalking页面 借鉴文章如下(如果涉及侵权，请联系作者进行删除、修改):官网构建社区中文版skywalking 开发环境编译及联调","categories":[{"name":"运维","slug":"运维","permalink":"http://zhuangyea.github.io/categories/运维/"},{"name":"SkyWalking","slug":"运维/SkyWalking","permalink":"http://zhuangyea.github.io/categories/运维/SkyWalking/"}],"tags":[{"name":"SkyWalking","slug":"SkyWalking","permalink":"http://zhuangyea.github.io/tags/SkyWalking/"}]},{"title":"使用docker-compose搭建SkyWalking环境","slug":"docker/使用docker-compose搭建SkyWalking环境","date":"2020-08-11T08:28:00.000Z","updated":"2020-08-13T11:48:24.904Z","comments":true,"path":"2020/08/11/docker/使用docker-compose搭建SkyWalking环境/","link":"","permalink":"http://zhuangyea.github.io/2020/08/11/docker/使用docker-compose搭建SkyWalking环境/","excerpt":"","text":"一、环境说明 Linux Centos7 ElasticSearch 7.8.0 SkyWalking 8.0.1 二、环境搭建 编写docker-compose.yml文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849version: '3.3'services: elasticsearch: image: elasticsearch:7.8.0 container_name: elasticsearch restart: always ports: - 9200:9200 environment: discovery.type: single-node TZ: Asia/Shanghai #volumes: # - ./elasticsearch/logs:/usr/share/elasticsearch/logs # - ./elasticsearch/data:/usr/share/elasticsearch/data # - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml ulimits: memlock: soft: -1 hard: -1 oap: image: apache/skywalking-oap-server:8.0.1-es7 container_name: oap depends_on: - elasticsearch links: - elasticsearch restart: always ports: - 11800:11800 - 12800:12800 environment: SW_STORAGE: elasticsearch7 # 指定ES版本 SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200 TZ: Asia/Shanghai # volumes: # - ./config/alarm-settings.yml:/skywalking/config/alarm-settings.yml ui: image: apache/skywalking-ui:8.0.1 container_name: ui depends_on: - oap links: - oap restart: always ports: - 8080:8080 environment: SW_OAP_ADDRESS: oap:12800 TZ: Asia/Shanghai 启动docker 启动容器：docker-compose up -d 查看容器：docker-compose ps 删除容器：docker-compose rm 验证 浏览器中输入：http://localhost:8080 三、Java应用接入 探针下载 apache-skywalking-apm-es7-8.0.1.tar.gz 其他版本下载 探针目录结构主要关注agent下的文件– config 配置文件存放位置– optional-plugins 选装插件，如果使用将jar文件移动到plugins下 idea配置探针 设置 VM options：-javaagent:/${Path}/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar 设置环境变量 SW_AGENT_NAME：项目名称 SW_AGENT_COLLECTOR_BACKEND_SERVICES：ip:port（oap服务地址） jar配置探针 java -jar -javaagent:/${Path}/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar -DSW_AGENT_NAME=项目名称 demo.jar 验证 四、nginx服务接入 参考skywalking-nginx-lua; Nginx代理为由Nginx LUA模块提供支持的Nginx提供了本机跟踪功能 我是使用openresty集成的，openresty启动时候指定skywalking-nginx-lua/examples/nginx.conf 效果图 五、题外话 相信不只我一人(至少我再群里看到的就不下10个人)因为下面这张图片，去开源群里问如何解决 解决方案就是因为少加了一个参数 归根结底是因为不去读文档，我就是因为老英文文档读不懂，一点点的就开始不读文档了。有问题百度、谷歌搜，搜不到就问人、加群问。直到被skywalking开源大佬吴晟怼了之后，才发现自己丢失了非常重要的读文档能力。非常感谢大佬点醒我！","categories":[{"name":"运维","slug":"运维","permalink":"http://zhuangyea.github.io/categories/运维/"},{"name":"SkyWalking","slug":"运维/SkyWalking","permalink":"http://zhuangyea.github.io/categories/运维/SkyWalking/"},{"name":"Docker","slug":"运维/SkyWalking/Docker","permalink":"http://zhuangyea.github.io/categories/运维/SkyWalking/Docker/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://zhuangyea.github.io/tags/运维/"},{"name":"Docker","slug":"Docker","permalink":"http://zhuangyea.github.io/tags/Docker/"},{"name":"SkyWalking","slug":"SkyWalking","permalink":"http://zhuangyea.github.io/tags/SkyWalking/"}]},{"title":"linux下docker环境及docker-compose环境安装","slug":"docker/docker环境及docker-compose环境安装","date":"2020-08-07T08:16:00.000Z","updated":"2020-08-14T11:37:13.119Z","comments":true,"path":"2020/08/07/docker/docker环境及docker-compose环境安装/","link":"","permalink":"http://zhuangyea.github.io/2020/08/07/docker/docker环境及docker-compose环境安装/","excerpt":"","text":"一、docker环境搭建官网安装地址 卸载旧版本 较旧的Docker版本称为docker或docker-engine。如果已安装这些程序，请卸载它们以及相关的依赖项。 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装依赖 12345sudo yum install -y yum-utilssudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装docker 1sudo yum install docker-ce docker-ce-cli containerd.io 查看docker版本 1docker -v 二、docker-compose环境搭建官网安装地址 运行以下命令以下载Docker Compose的当前稳定版本 1sudo curl -L \"https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 将可执行权限应用于二进制文件 1sudo chmod +x /usr/local/bin/docker-compose 查看docker-compose版本 1docker-compose -v 三、docker配置文件修改 修改配置文件（如果文件不存在，创建一个） vim /etc/docker/daemon.json 12345678910111213&#123; \"debug\": true, \"registry-mirrors\": [ \"http://hub-mirror.c.163.com\", \"https://registry.aliyuncs.com\", \"https://registry.docker-cn.com\", \"https://docker.mirrors.ustc.edu.cn\" ], \"insecure-registries\": [ \"ip:host\" ], \"experimental\": true&#125; 重启dockersystemctl start docker.servicesystemctl status docker.service 四、docker常用命令 容器命令 12345678910docker ps # 查看正在运行容器docker ps -a # 查看所有容器docker run -dit --name=crawld -p 30030:10002 deb7db7d4b75 # 启动容器。对外端口：容器端口docker logs --details 82d68c1534c6 # 查看日志docker logs -f -t --since=\"2020-05-29\" --tail=10 b18698736657 # 查看指定日期之后的日志docker stop 82d68c1534c6 # 停止容器docker rmf deb7db7d4b75 # 删除容器docker exec -it 97191593e2b2 /bin/bash # 进入容器docker tag skywalking/ui:8.0.1 ip:port/basic-servers/skywalking-ui:8.0.1 # Tag标记本地镜像docker push ip:port/basic-servers/skywalking-ui:8.0.1 # 镜像上传 镜像命令 123docker pull docker.io/airdock/oracle-jdk # 拉取镜像（jdk为例）docker build -t api-gateway:v1 . # 生成镜像。将当前目录打包并生成名字叫api-gateway的镜像docker rmi api-gateway:v1 # 删除镜像 五、docker-compose docker-compose命令 1234docker-compose up -d # 启动容器docker-compose stop # 停止容器docker-compose rm # 删除容器docker-compose restart # 重启容器 docker-compose.yml示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657version: '3.3'services: elasticsearch: image: elasticsearch:7.1.1 container_name: elasticsearch restart: always privileged: true user: root ports: - 9200:9200 environment: discovery.type: single-node TZ: Asia/Shanghai volumes: - ./elasticsearch/logs:/usr/share/elasticsearch/logs - ./elasticsearch/data:/usr/share/elasticsearch/data - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml #- /etc/localtime:/etc/localtime ulimits: memlock: soft: -1 hard: -1 oap: image: skywalking-oap:8.0.1 container_name: oap depends_on: - elasticsearch links: - elasticsearch restart: always ports: - 11800:11800 - 12800:12800 environment: SW_STORAGE: elasticsearch7 SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200 TZ: Asia/Shanghai volumes: - ./config/alarm-settings.yml:/skywalking/config/alarm-settings.yml #- /etc/localtime:/etc/localtime # - ./config/server-core-6.6.0.jar:/skywalking/oap-libs/server-core-6.6.0.jar # - ./config/storage-elasticsearch-plugin-6.6.0.jar:/skywalking/oap-libs/storage-elasticsearch-plugin-6.6.0.jar ui: image: skywalking-ui:8.0.1 container_name: ui depends_on: - oap links: - oap restart: always ports: - 8080:8080 environment: SW_OAP_ADDRESS: oap:12800 TZ: Asia/Shanghai #volumes: # - /etc/localtime:/etc/localtime","categories":[{"name":"运维","slug":"运维","permalink":"http://zhuangyea.github.io/categories/运维/"},{"name":"docker","slug":"运维/docker","permalink":"http://zhuangyea.github.io/categories/运维/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://zhuangyea.github.io/tags/docker/"}]},{"title":"Alibaba canal组件的安装及使用","slug":"alibaba/canal安装及使用-JAVA","date":"2020-04-27T11:36:00.000Z","updated":"2020-04-29T08:23:26.663Z","comments":true,"path":"2020/04/27/alibaba/canal安装及使用-JAVA/","link":"","permalink":"http://zhuangyea.github.io/2020/04/27/alibaba/canal安装及使用-JAVA/","excerpt":"","text":"一、前言：环境准备 蓝色字体可点击，安装包下载 Linux MySql 5.7 canal 1.1.4 canal-admin 1.1.4 kafka_2.12-2.5.0 apache-zookeeper-3.6.0 二、名词解释 canal [kə’næl]，译意为水道/管道/沟渠，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费 canal-admin 设计上是为canal提供整体配置管理、节点运维等面向运维的功能，提供相对友好的WebUI操作界面，方便更多用户快速和安全的操作 Canal Kafka RocketMQ QuickStart canal 1.1.1版本之后, 默认支持将canal server接收到的binlog数据直接投递到MQ, 目前默认支持的MQ系统有: kafka: https://github.com/apache/kafka RocketMQ : https://github.com/apache/rocketmq 三、canal + SpringBoot模式3.1 canal准备 对于自建 MySQL , 需要先开启 Binlog 写入功能，配置 binlog-format 为 ROW 模式，my.cnf 中配置如下 1234[mysqld]log-bin=mysql-bin # 开启 binlogbinlog-format=ROW # 选择 ROW 模式server_id=1 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复 注意：针对阿里云 RDS for MySQL , 默认打开了 binlog , 并且账号默认具有 binlog dump 权限 , 不需要任何权限或者 binlog 设置,可以直接跳过这一步 授权 canal 链接 MySQL 账号具有作为 MySQL slave 的权限, 如果已有账户可直接 grant 1234CREATE USER canal IDENTIFIED BY &apos;canal&apos;; GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &apos;canal&apos;@&apos;%&apos;;-- GRANT ALL PRIVILEGES ON *.* TO &apos;canal&apos;@&apos;%&apos; ;FLUSH PRIVILEGES; 3.2 canal启动 下载 canal, 访问 release 页面 , 选择需要的包下载, 如以 1.1.4 版本为例 wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.deployer-1.1.4.tar.gz 解压完成后，进入 canal 目录，可以看到如下结构 配置修改 vim conf/example/instance.properties #position info，需要改成自己的数据库信息 canal.instance.master.address = 127.0.0.1:3306 canal.instance.dbUsername = root canal.instance.dbPassword = 123456 # mq config canal.mq.topic=mytopic 启动 sh bin/startup.sh 查看 server 日志 tail -f logs/canal/canal.log 查看 instance 的日志 tail -f logs/example/example.log 关闭 sh bin/stop.sh 3.3 让canal成为SpringBoot组件 下载SpringBoot canal项目 项目地址 修改配置文件 canal-test/application.properties 注意：红框中的配置要与canal配置文件instance.properties所在目录匹配 启动canal-test 测试，修改本地库数据，查看控制台 四、canal + canal-admin + MQ模式（单节点）zookeeper+kafka安装过程省略 4.1 canal-admin准备 canal-admin的限定依赖： MySQL，用于存储配置和节点等相关数据 canal版本，要求&gt;=1.1.4 (需要依赖canal-server提供面向admin的动态运维管理接口) 部署 下载 canal-admin, 访问 release 页面 , 选择需要的包下载, 如以 1.1.4 版本为例 wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.admin-1.1.4.tar.gz 解压完成后，进入 canal-admin 目录，可以看到如下结构 配置修改vim conf/application.yml 123456789101112131415161718192021server: port: 8089spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8spring.datasource: address: 127.0.0.1:3306 database: canal_manager username: canal password: canal driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://$&#123;spring.datasource.address&#125;/$&#123;spring.datasource.database&#125;?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false hikari: maximum-pool-size: 30 minimum-idle: 1canal: adminUser: admin adminPasswd: 123456 初始化元数据库 mysql -h127.1 -uroot -p # 导入初始化SQL &gt; source conf/canal_manager.sql 启动sh bin/startup.sh 查看 admin 日志tail -f logs/admin.log 此时代表canal-admin已经启动成功，可以通过 http://127.0.0.1:8089/ 访问，默认密码：admin/123456 关闭sh bin/stop.sh 4.2 canal-server启动 修改配置文件vim conf/canal_local.properties 1234567891011# register ipcanal.register.ip = 172.17.7.81 #canal服务所在服务器IP# canal admin configcanal.admin.manager = 172.17.7.81:8089canal.admin.port = 11110canal.admin.user = admincanal.admin.passwd = 6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9# admin auto registercanal.admin.register.auto = truecanal.admin.register.cluster = 配置密码上面配置的webUI的密码暗文需要到mysql的数据库查询的，我们配置的密码是123456，所以需要到数据库产生 1234567mysql&gt; select password(123456);+-------------------------------------------+| password(123456) |+-------------------------------------------+| *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |+-------------------------------------------+1 row in set, 1 warning (0.00 sec) 启动canal服务要使用canal-admin，所以在启动方面也有一点不同，在bin目录下执行startup.sh 传入参数local1234567# 启动方法一：sh bin/startup.sh local# 启动方法二：# ---将canal_local.properties配置文件的名字改成canal.properties(删除原有的)sh bin/startup.sh 4.3 webUI的使用 官方介绍文档 Server管理截图 新增 配置Server 操作-&gt;配置 载入模板，修改模板1234567891011121314151617181920# tcp, kafka, RocketMQcanal.serverMode = kafka########################################################### MQ ###############################################################canal.mq.servers = 127.0.0.1:9092canal.mq.retries = 0canal.mq.batchSize = 16384canal.mq.maxRequestSize = 1048576canal.mq.lingerMs = 100canal.mq.bufferMemory = 33554432canal.mq.canalBatchSize = 50canal.mq.canalGetTimeout = 100canal.mq.flatMessage = truecanal.mq.compressionType = nonecanal.mq.acks = all#canal.mq.properties. =canal.mq.producerGroup = test# Set this value to &quot;cloud&quot;, if you want open message trace feature in aliyun.canal.mq.accessChannel = local 保存，并返回 Instance管理截图 新增、配置Instance 1234567# position infocanal.instance.master.address=127.0.0.1:3306# username/passwordcanal.instance.dbUsername=rootcanal.instance.dbPassword=12345678s# mq configcanal.mq.topic=mytopic 保存并返回 4.4 测试 五、至此单节点canal秘籍已练成！开森 借鉴文章如下（侵删）：canal-admin的高可用使用，单机使用，HA使用，阿里的canal的UI界面，管理canal的实例让canal成为SpringBoot组件","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://zhuangyea.github.io/tags/java/"},{"name":"alibaba","slug":"alibaba","permalink":"http://zhuangyea.github.io/tags/alibaba/"}]},{"title":"Python爬虫技术/框架比对","slug":"python/Python爬虫技术/框架比对","date":"2020-04-15T02:00:00.000Z","updated":"2020-04-15T05:25:37.521Z","comments":true,"path":"2020/04/15/python/Python爬虫技术/框架比对/","link":"","permalink":"http://zhuangyea.github.io/2020/04/15/python/Python爬虫技术/框架比对/","excerpt":"","text":"技术 区别 描述 Scrapy框架 主流爬虫框架不适合新手扩展性高 Scrapy框架是一套比较成熟的Python爬虫框架，是使用Python开发的快速、高层次的信息爬取框架，可以高效的爬取web页面并提取出结构化数据 Portia框架 无需编程基础无需开发页面配置 Portia框架是一款允许没有任何编程基础的用户可视化地爬取网页的爬虫框架 Crawley框架 无 Crawley也是Python开发出的爬虫框架，该框架致力于改变人们从互联网中提取数据的方式 借鉴文章如下（侵删）：Python有哪些常见的、好用的爬虫框架？","categories":[{"name":"Python","slug":"Python","permalink":"http://zhuangyea.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://zhuangyea.github.io/tags/Python/"}]},{"title":"SQL函数","slug":"db/SQL函数","date":"2019-09-06T07:00:00.000Z","updated":"2019-12-19T09:16:51.957Z","comments":true,"path":"2019/09/06/db/SQL函数/","link":"","permalink":"http://zhuangyea.github.io/2019/09/06/db/SQL函数/","excerpt":"","text":"SQL中字符串截取函数(SUBSTRING) left（name,4）截取左边的4个字符 SELECT LEFT(201809,4) 年 结果：2018 right（name,2）截取右边的2个字符 SELECT RIGHT(201809,2) 月份 结果：09 SUBSTRING(name,5,3) 截取name这个字段 从第五个字符开始 只截取之后的3个字符 SELECT SUBSTRING(‘成都融资事业部’,5,3) 结果：事业部 SUBSTRING(name,3) 截取name这个字段 从第三个字符开始，之后的所有个字符 SELECT SUBSTRING(‘成都融资事业部’,3) 结果：融资事业部 SUBSTRING(name, -4) 截取name这个字段的第 4 个字符位置（倒数）开始取，直到结束 SELECT SUBSTRING(‘成都融资事业部’,-4) 结果：资事业部 SUBSTRING(name, -4，2) 截取name这个字段的第 4 个字符位置（倒数）开始取，只截取之后的2个字符 SELECT SUBSTRING(‘成都融资事业部’,-4,2) 结果：资事 注意：我们注意到在函数 substring(str,pos, len)中， pos 可以是负值，但 len 不能取负值。 substring_index(‘www.baidu.com&#39;, ‘.’, 2) 截取第二个 ‘.’ 之前的所有字符 SELECT substring_index(‘www.baidu.com&#39;, ‘.’, 2) 结果：www.baidu substring_index(‘www.baidu.com&#39;, ‘.’, -2) 截取第二个 ‘.’ （倒数）之后的所有字符 SELECT substring_index(‘www.baidu.com&#39;, ‘.’, -2) 结果：baidu.com SUBSTR(name, 1, CHAR_LENGTH(name)-3) 截取name字段，取除name字段后三位的所有字符SELECT SUBSTR(‘成都融资事业部’, 1, CHAR_LENGTH(‘成都融资事业部’)-3) SQL时间函数 俩个时间相减后取分钟 123456789TIMESTAMPDIFF(MINUTE,entry_time,out_time) out_time减去entry_time相减后得到分钟，如果后者小于前者分钟为负数。interval可是： - SECOND 秒 SECONDS - MINUTE 分钟 MINUTES - HOUR 时间 HOURS - DAY 天 DAYS - MONTH 月 MONTHS - YEAR 年 YEARS 转载于：SQL中字符串截取函数(SUBSTRING)","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://zhuangyea.github.io/tags/数据库/"}]},{"title":"SpringBoot整合Redis及工具类编写","slug":"java/SpringBoot整合Redis及工具类编写","date":"2019-08-22T09:35:00.000Z","updated":"2019-08-22T07:29:05.238Z","comments":true,"path":"2019/08/22/java/SpringBoot整合Redis及工具类编写/","link":"","permalink":"http://zhuangyea.github.io/2019/08/22/java/SpringBoot整合Redis及工具类编写/","excerpt":"","text":"一、简介SpringBoot框架中已经集成了redis，在1.x.x的版本时默认使用的jedis客户端，现在是2.x.x版本默认使用的lettuce客户端，两种客户端的区别如下： Jedis和Lettuce都是Redis Client Jedis 是直连模式，在多个线程间共享一个 Jedis 实例时是线程不安全的， 如果想要在多线程环境下使用 Jedis，需要使用连接池，每个线程都去拿自己的 Jedis 实例，当连接数量增多时，物理连接成本就较高了。 Lettuce的连接是基于Netty的，连接实例可以在多个线程间共享，所以，一个多线程的应用可以使用同一个连接实例，而不用担心并发线程的数量。当然这个也是可伸缩的设计，一个连接实例不够的情况也可以按需增加连接实例。 通过异步的方式可以让我们更好的利用系统资源，而不用浪费线程等待网络或磁盘I/O。 Lettuce 是基于 netty 的，netty 是一个多线程、事件驱动的 I/O 框架，所以 Lettuce 可以帮助我们充分利用异步的优势。 二、jedis客户端模式 1. Maven依赖（先在pom中引入redis及其它jar包） 123456&lt;!-- spring 1.5之后spring boot 的自带的Jedis的版本就是2.9.0, 低于该版本启动报错 --&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; yml配置文件中加入redis相关配置 123456datasource: redis: host: localhost port: 30539 database: 13 password: Redis工具类编写 点击下载 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581import com.alibaba.fastjson.JSON;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;import redis.clients.jedis.*;import javax.annotation.PostConstruct;import java.lang.reflect.Field;import java.util.*;/** * redis工具类 * * @author Colin.Ye * @version 1.0 * @ClassName RedisController * @date 2018/1/12 **/@Componentpublic class RedisUtil &#123; final Logger logger = LoggerFactory.getLogger(getClass()); /** * 数据源 */ private ShardedJedisPool shardedJedisPool; @Value(\"$&#123;datasource.redis.host&#125;\") private String host; @Value(\"$&#123;datasource.redis.port&#125;\") private int port; @Value(\"$&#123;datasource.redis.database&#125;\") private int db; /** * 切换redis库 * * @param jedis */ private void setDb(JedisShardInfo jedis) &#123; Class&lt;? extends JedisShardInfo&gt; clz = jedis.getClass(); Field declaredField = null; try &#123; declaredField = clz.getDeclaredField(\"db\"); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; declaredField.setAccessible(true); try &#123; declaredField.set(jedis, db); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; @PostConstruct public void init() &#123; JedisPoolConfig config = new JedisPoolConfig();// Jedis池配置// TODO 从配置文件读取配置// config.setMaxTotal(Integer.MAX_VALUE); // 最大连接数, 默认8个 config.setMaxIdle(1000 * 60);// 对象最大空闲时间 config.setMaxWaitMillis(1000 * 20);// 获取对象时最大等待时间 config.setTestOnBorrow(false);// TODO 根据配置文件线程数量循环创建连接 List&lt;JedisShardInfo&gt; jdsInfoList = new ArrayList&lt;JedisShardInfo&gt;(1); JedisShardInfo infoA = new JedisShardInfo(host, port); setDb(infoA); jdsInfoList.add(infoA); JedisShardInfo infoB = new JedisShardInfo(host, port); setDb(infoB); jdsInfoList.add(infoB); JedisShardInfo infoC = new JedisShardInfo(host, port); setDb(infoC); jdsInfoList.add(infoC); this.shardedJedisPool = new ShardedJedisPool(config, jdsInfoList);// jedis = shardedJedisPool.getResource(); &#125; /** * 获取数据库连接 * * @return conn */ public ShardedJedis getConnection() &#123; ShardedJedis jedis = null; try &#123; jedis = shardedJedisPool.getResource(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return jedis; &#125; /** * 关闭数据库连接 * * @param conn */ public void closeConnection(ShardedJedis jedis) &#123; if (null != jedis) &#123; try &#123;// shardedJedisPool.returnResource(jedis); jedis.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;// /**// * 获取jedis// * @return// */// public ShardedJedis jedis()&#123;// return this.jedis;// &#125; /** * 设置数据 * * @param conn */ public boolean setData(String key, String value) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); jedis.set(key, value); return true; &#125; catch (Exception e) &#123; System.out.println(e); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; public Long llen(String key) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Long l = jedis.llen(key); return l; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return 0L; &#125; /** * 设置数据 * * @param conn */ public boolean rpush(String key, String value) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); jedis.rpush(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; /** * 设置数据 * * @param conn */ public boolean sadd(String key, String value) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); jedis.sadd(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; /** * 获取数据 * * @param conn */ public String getData(String key) &#123; String value = null; ShardedJedis jedis = null; try &#123; jedis = getConnection(); value = jedis.get(key); return value; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return value; &#125; public boolean isMember(String key, String member) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); boolean result = jedis.sismember(key, member); return result; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; public Set&lt;String&gt; smembers(String key) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Set&lt;String&gt; s = jedis.smembers(key); return s; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return null; &#125; /** * 获取List集合 * * @param key * @param clazz * @return */ @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) public List getListJsonData(String key, Class clazz) &#123; List&lt;String&gt; userList = null; List list = new ArrayList(); ShardedJedis jedis = null; try &#123; jedis = getConnection(); userList = jedis.lrange(key, 0, -1); for (String str : userList) &#123; list.add(JSON.parseObject(str, clazz)); &#125; return list; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return list; &#125; /** * 使用rpush方式插入List集合 * * @param key * @param clazz * @return */ public boolean rpushJsonData(String key, Object o) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); jedis.rpush(key, JSON.toJSONString(o)); logger.info(o.toString()); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; /** * 存储map格式数据（map的key和value必须是String） * * @param key * @return */ public boolean hmset(String key, Map&lt;String, String&gt; params) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); jedis.hmset(key, params); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; /** * 查询map格式数据（map的key和value必须是String） * * @param key * @param obj 可以为LIST、SET、数组、字符串 * @return 返回list集合 */ public List&lt;Map&lt;String, String&gt;&gt; hmget(String key, Object obj) &#123; ShardedJedis jedis = getConnection(); String[] array = &#123;&#125;; String str = null; if (obj instanceof String) &#123; str = obj.toString().replace(\" \", \"\"); array = str.split(\",\"); &#125; else if (obj instanceof List || obj instanceof Set) &#123; str = obj.toString().replace(\" \", \"\"); str = str.substring(1, str.length() - 1); array = str.split(\",\"); &#125; else if (obj instanceof String[]) &#123; array = (String[]) obj; &#125; List&lt;Map&lt;String, String&gt;&gt; list = new ArrayList&lt;Map&lt;String, String&gt;&gt;(); List&lt;String&gt; cities = jedis.hmget(key, array); for (int i = 0; i &lt; array.length; i++) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(array[i], cities.get(i)); list.add(map); &#125; closeConnection(jedis); return list; &#125; /** * 查询map格式数据（返回所有map） * * @param key * @return 返回list集合 */ public Map&lt;String, String&gt; hgetAll(String key) &#123; ShardedJedis jedis = getConnection(); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); try &#123; map = jedis.hgetAll(key); return map; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return map; &#125; public boolean setJsonData(String key, Object o) &#123; ShardedJedis jedis = null; try &#123; jedis = shardedJedisPool.getResource(); jedis.set(key, JSON.toJSONString(o)); logger.info(o.toString()); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; @SuppressWarnings(\"all\") public Object getJsonData(String key, Class clazz) &#123; String value = null; ShardedJedis jedis = null; try &#123; jedis = shardedJedisPool.getResource(); value = jedis.get(key);// shardedJedisPool.returnResource(jedis); return JSON.parseObject(value, clazz); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return null; &#125; public String lpop(final String key) &#123; String value = null; ShardedJedis jedis = null; try &#123; jedis = getConnection(); value = jedis.lpop(key); return value; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return value; &#125; public Boolean sismember(final String key, final String member) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Boolean value = jedis.sismember(key, member); return value; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; public Long zadd(final String key, int score, String member) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Long l = jedis.zadd(key, score, member); return l; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return 0L; &#125; public Set&lt;String&gt; zrevrange(final String key, int start, int end) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Set&lt;String&gt; s = jedis.zrevrange(key, start, end); return s; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return null; &#125; public String zrevrangeByscore(final String key) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Set&lt;String&gt; s = jedis.zrevrangeByScore(key, \"+inf\", \"-inf\"); Iterator&lt;String&gt; it = s.iterator(); while (it.hasNext()) &#123; return (String) it.next(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return null; &#125; public Set&lt;Tuple&gt; zrevrangeWithScores(final String key, int start, int end) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Set&lt;Tuple&gt; set = jedis.zrevrangeWithScores(key, start, end); return set; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return null; &#125; public int zincrby(final String key, int score, String member) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Double d = jedis.zincrby(key, score, member); return d.intValue(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return 0; &#125; public int zscore(final String key, String member) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); Double d = jedis.zscore(key, member); if (d == null) &#123; return 0; &#125; return d.intValue(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return 0; &#125; /** * 删除数据 * * @param key * @return */ public long del(String key) &#123; ShardedJedis jedis = null; try &#123; jedis = getConnection(); long count = jedis.del(key); return count; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return 0; &#125; /** * 设置过期时间 * * @param key * @param seconds 秒 * @return */ public boolean expire(String key, int seconds) &#123; ShardedJedis jedis = null; try &#123; jedis = shardedJedisPool.getResource(); jedis.expire(key, seconds); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; closeConnection(jedis); &#125; return false; &#125; /** * 设置连接池 * * @return 数据源 */ public void setShardedJedisPool(ShardedJedisPool shardedJedisPool) &#123; this.shardedJedisPool = shardedJedisPool; &#125; /** * 获取连接池 * * @return 数据源 */ public ShardedJedisPool getShardedJedisPool() &#123; return shardedJedisPool; &#125;&#125; 三、lettuce客户端模式 1. Maven依赖（先在pom中引入redis及其它jar包） 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.commons/commons-pool2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.4.2&lt;/version&gt;&lt;/dependency&gt; yml配置文件中加入redis相关配置 12345678910111213spring: redis: host: localhost # Redis服务器地址 port: 30539 # Redis服务器连接端口 database: 13 # Redis数据库索引（默认为0） password: # Redis服务器连接密码（默认为空） timeout: 10000ms # 连接超时时间（毫秒） lettuce: pool: max-active: 200 # 连接池最大连接数（使用负值表示没有限制） max-wait: -1ms # 连接池最大阻塞等待时间（使用负值表示没有限制） max-idle: 10 # 连接池中的最大空闲连接 min-idle: 0 # 连接池中的最小空闲连接 Redis配置类编写 点击下载SpringBoot自动帮我们在容器中生成了一个RedisTemplate和一个StringRedisTemplate。但是，这个RedisTemplate的泛型是&lt;Object,Object&gt;，写代码不方便，需要写好多类型转换的代码；我们需要一个泛型为&lt;String,Object&gt;形式的RedisTemplate。并且，这个RedisTemplate没有设置数据存在Redis时，key及value的序列化方式。 12345678910111213141516171819202122232425262728293031323334353637383940414243import com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * redis配置类 * * @author Colin.Ye * @version 1.0 * @ClassName RedisConfig * @date 2019/8/22 **/@Configurationpublic class RedisConfig &#123; @Bean @SuppressWarnings(\"all\") public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;String, Object&gt;(); template.setConnectionFactory(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // key采用String的序列化方式 template.setKeySerializer(stringRedisSerializer); // hash的key也采用String的序列化方式 template.setHashKeySerializer(stringRedisSerializer); // value序列化方式采用jackson template.setValueSerializer(jackson2JsonRedisSerializer); // hash的value序列化方式采用jackson template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; &#125;&#125; Redis工具类编写 点击下载 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Component;import org.springframework.util.CollectionUtils;import java.util.List;import java.util.Map;import java.util.Set;import java.util.concurrent.TimeUnit;/** * Redis工具类 * * @author Colin.Ye * @version 1.0 * @ClassName RedisUtil * @date 2019/8/22 **/@Componentpublic class RedisUtil &#123; @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; // =============================common============================ /** * 指定缓存失效时间 * * @param key 键 * @param time 时间(秒) * @return */ public boolean expire(String key, long time) &#123; try &#123; if (time &gt; 0) &#123; redisTemplate.expire(key, time, TimeUnit.SECONDS); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 根据key 获取过期时间 * * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ public long getExpire(String key) &#123; return redisTemplate.getExpire(key, TimeUnit.SECONDS); &#125; /** * 判断key是否存在 * * @param key 键 * @return true 存在 false不存在 */ public boolean hasKey(String key) &#123; try &#123; return redisTemplate.hasKey(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 删除缓存 * * @param key 可以传一个值 或多个 */ @SuppressWarnings(\"unchecked\") public void del(String... key) &#123; if (key != null &amp;&amp; key.length &gt; 0) &#123; if (key.length == 1) &#123; redisTemplate.delete(key[0]); &#125; else &#123; redisTemplate.delete(CollectionUtils.arrayToList(key)); &#125; &#125; &#125; // ============================String============================= /** * 普通缓存获取 * * @param key 键 * @return 值 */ public Object get(String key) &#123; return key == null ? null : redisTemplate.opsForValue().get(key); &#125; /** * 普通缓存放入 * * @param key 键 * @param value 值 * @return true成功 false失败 */ public boolean set(String key, Object value) &#123; try &#123; redisTemplate.opsForValue().set(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 普通缓存放入并设置时间 * * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 * @return true成功 false 失败 */ public boolean set(String key, Object value, long time) &#123; try &#123; if (time &gt; 0) &#123; redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS); &#125; else &#123; set(key, value); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 递增 * * @param key 键 * @param delta 要增加几(大于0) * @return */ public long incr(String key, long delta) &#123; if (delta &lt; 0) &#123; throw new RuntimeException(\"递增因子必须大于0\"); &#125; return redisTemplate.opsForValue().increment(key, delta); &#125; /** * 递减 * * @param key 键 * @param delta 要减少几(小于0) * @return */ public long decr(String key, long delta) &#123; if (delta &lt; 0) &#123; throw new RuntimeException(\"递减因子必须大于0\"); &#125; return redisTemplate.opsForValue().increment(key, -delta); &#125; // ================================Map================================= /** * HashGet * * @param key 键 不能为null * @param item 项 不能为null * @return 值 */ public Object hget(String key, String item) &#123; return redisTemplate.opsForHash().get(key, item); &#125; /** * 获取hashKey对应的所有键值 * * @param key 键 * @return 对应的多个键值 */ public Map&lt;Object, Object&gt; hmget(String key) &#123; return redisTemplate.opsForHash().entries(key); &#125; /** * HashSet * * @param key 键 * @param map 对应多个键值 * @return true 成功 false 失败 */ public boolean hmset(String key, Map&lt;String, Object&gt; map) &#123; try &#123; redisTemplate.opsForHash().putAll(key, map); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * HashSet 并设置时间 * * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) * @return true成功 false失败 */ public boolean hmset(String key, Map&lt;String, Object&gt; map, long time) &#123; try &#123; redisTemplate.opsForHash().putAll(key, map); if (time &gt; 0) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @return true 成功 false失败 */ public boolean hset(String key, String item, Object value) &#123; try &#123; redisTemplate.opsForHash().put(key, item, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 * @return true 成功 false失败 */ public boolean hset(String key, String item, Object value, long time) &#123; try &#123; redisTemplate.opsForHash().put(key, item, value); if (time &gt; 0) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 删除hash表中的值 * * @param key 键 不能为null * @param item 项 可以使多个 不能为null */ public void hdel(String key, Object... item) &#123; redisTemplate.opsForHash().delete(key, item); &#125; /** * 判断hash表中是否有该项的值 * * @param key 键 不能为null * @param item 项 不能为null * @return true 存在 false不存在 */ public boolean hHasKey(String key, String item) &#123; return redisTemplate.opsForHash().hasKey(key, item); &#125; /** * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * * @param key 键 * @param item 项 * @param by 要增加几(大于0) * @return */ public double hincr(String key, String item, double by) &#123; return redisTemplate.opsForHash().increment(key, item, by); &#125; /** * hash递减 * * @param key 键 * @param item 项 * @param by 要减少记(小于0) * @return */ public double hdecr(String key, String item, double by) &#123; return redisTemplate.opsForHash().increment(key, item, -by); &#125; // ============================set============================= /** * 根据key获取Set中的所有值 * * @param key 键 * @return */ public Set&lt;Object&gt; sGet(String key) &#123; try &#123; return redisTemplate.opsForSet().members(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 根据value从一个set中查询,是否存在 * * @param key 键 * @param value 值 * @return true 存在 false不存在 */ public boolean sHasKey(String key, Object value) &#123; try &#123; return redisTemplate.opsForSet().isMember(key, value); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 将数据放入set缓存 * * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ public long sSet(String key, Object... values) &#123; try &#123; return redisTemplate.opsForSet().add(key, values); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 将set数据放入缓存 * * @param key 键 * @param time 时间(秒) * @param values 值 可以是多个 * @return 成功个数 */ public long sSetAndTime(String key, long time, Object... values) &#123; try &#123; Long count = redisTemplate.opsForSet().add(key, values); if (time &gt; 0) &#123; expire(key, time); &#125; return count; &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 获取set缓存的长度 * * @param key 键 * @return */ public long sGetSetSize(String key) &#123; try &#123; return redisTemplate.opsForSet().size(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 移除值为value的 * * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ public long setRemove(String key, Object... values) &#123; try &#123; Long count = redisTemplate.opsForSet().remove(key, values); return count; &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; // ===============================list================================= /** * 获取list缓存的内容 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return */ public List&lt;Object&gt; lGet(String key, long start, long end) &#123; try &#123; return redisTemplate.opsForList().range(key, start, end); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 获取list缓存的长度 * * @param key 键 * @return */ public long lGetListSize(String key) &#123; try &#123; return redisTemplate.opsForList().size(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 通过索引 获取list中的值 * * @param key 键 * @param index 索引 index&gt;=0时， 0 表头，1 第二个元素，依次类推；index&lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * @return */ public Object lGetIndex(String key, long index) &#123; try &#123; return redisTemplate.opsForList().index(key, index); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 将list放入缓存 * * @param key 键 * @param value 值 * // * @param time 时间(秒) * @return */ public boolean lSet(String key, Object value) &#123; try &#123; redisTemplate.opsForList().rightPush(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ public boolean lSet(String key, Object value, long time) &#123; try &#123; redisTemplate.opsForList().rightPush(key, value); if (time &gt; 0) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 将list放入缓存 * * @param key 键 * @param value 值 * // * @param time 时间(秒) * @return */ public boolean lSet(String key, List&lt;Object&gt; value) &#123; try &#123; redisTemplate.opsForList().rightPushAll(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ public boolean lSet(String key, List&lt;Object&gt; value, long time) &#123; try &#123; redisTemplate.opsForList().rightPushAll(key, value); if (time &gt; 0) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 根据索引修改list中的某条数据 * * @param key 键 * @param index 索引 * @param value 值 * @return */ public boolean lUpdateIndex(String key, long index, Object value) &#123; try &#123; redisTemplate.opsForList().set(key, index, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 移除N个值为value * * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ public long lRemove(String key, long count, Object value) &#123; try &#123; Long remove = redisTemplate.opsForList().remove(key, count, value); return remove; &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125;&#125; 借鉴文章如下:SpringBoot整合Redis及Redis工具类撰写spring boot 集成 redis lettuce","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://zhuangyea.github.io/tags/java/"}]},{"title":"Springboot-使用RestTemplate方式发HTTP请求及上传文件","slug":"java/Springboot-使用RestTemplate方式发HTTP请求及上传文件","date":"2019-08-09T10:35:00.000Z","updated":"2019-09-09T02:14:27.355Z","comments":true,"path":"2019/08/09/java/Springboot-使用RestTemplate方式发HTTP请求及上传文件/","link":"","permalink":"http://zhuangyea.github.io/2019/08/09/java/Springboot-使用RestTemplate方式发HTTP请求及上传文件/","excerpt":"","text":"RestTemplate是Spring提供的用于访问Rest服务的客户端，RestTemplate提供了多种便捷访问远程Http服务的方法,能够大大提高客户端的编写效率。 我基于RestTemplate编写了一个工具类，方便使用。工具类提供之提供了GET、POST、DELETE请求方法，其他方法自行补充 Application启动类中实例RestTemplate 1234567891011121314@SpringBootApplication@RestControllerpublic class Applicatiohexn &#123; public static void main(String[] args) &#123; SpringApplication.run(ElasticApplication.class, args); &#125; @Bean public RestTemplate restTemplate() &#123; // new HttpComponentsClientHttpRequestFactory()作用：支持patch请求 RestTemplate restTemplate = new RestTemplate(new HttpComponentsClientHttpRequestFactory());// restTemplate.getMessageConverters().set(1, new StringHttpMessageConverter(StandardCharsets.UTF_8)); return restTemplate; &#125;&#125; RestTemplateUtils工具类 点击下载 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.ResponseEntity;import org.springframework.stereotype.Component;import org.springframework.util.LinkedMultiValueMap;import org.springframework.util.MultiValueMap;import org.springframework.web.client.RestTemplate;import java.util.ArrayList;import java.util.LinkedHashMap;import java.util.List;import java.util.Map;/** * RestTemplate工具类 * * @author Colin.Ye * @version 1.0 * @ClassName RestTemplateUtils * @date 2019/7/31 **/@Componentpublic class RestTemplateUtils &#123; @Autowired private RestTemplate restTemplate; /** * POST请求-JSON参数 * * @param url * @param params * @param headers * @return */ public &lt;T&gt; T httpPostJson(String url, Map params, Map headers, Class&lt;T&gt; clazz) &#123; HttpHeaders httpHeaders = new HttpHeaders(); if (headers != null) &#123; headers.forEach((o1, o2) -&gt; httpHeaders.add(o1.toString(), o2.toString())); &#125; // json方式传参 return restTemplate.postForObject(url, new HttpEntity(params, httpHeaders), clazz); &#125; /** * POST请求-FROM参数 * * @param url * @param params * @param headers * @return */ public &lt;T&gt; T httpPostForm(String url, Map params, Map headers, Class&lt;T&gt; clazz) &#123; HttpHeaders httpHeaders = new HttpHeaders(); params = params == null ? new LinkedHashMap&lt;&gt;() : params; if (headers != null) &#123; headers.forEach((o1, o2) -&gt; httpHeaders.add(o1.toString(), o2.toString())); &#125; MultiValueMap&lt;String, Object&gt; stringObjectLinkedMultiValueMap = new LinkedMultiValueMap&lt;&gt;(); params.forEach((o1, o2) -&gt; stringObjectLinkedMultiValueMap.add(o1.toString(), o2)); // 表单方式传参 // json方式传参 return restTemplate.postForObject(url, new HttpEntity(stringObjectLinkedMultiValueMap, httpHeaders), clazz); &#125; /** * GET请求-?号参数 * * @param url * @param params * @param headers * @return */ public &lt;T&gt; T httpGetTraditional(String url, Map params, Map headers, Class&lt;T&gt; clazz) &#123; HttpHeaders httpHeaders = new HttpHeaders(); params = params == null ? new LinkedHashMap&lt;&gt;() : params; if (headers != null) &#123; headers.forEach((o1, o2) -&gt; httpHeaders.add(o1.toString(), o2.toString())); &#125; StringBuilder sb = new StringBuilder(url); sb.append(\"?\"); params.forEach((o1, o2) -&gt; sb.append(o1).append(\"=\").append(o2).append(\"&amp;\")); url = sb.toString().replaceAll(\"&amp;$+|\\\\?$+\", \"\"); ResponseEntity&lt;T&gt; exchange = restTemplate.exchange(url, HttpMethod.GET, new HttpEntity(null, httpHeaders), clazz); return exchange.getBody(); &#125; /** * GET请求-分隔符参数 * * @param url * @param params * @param headers * @return */ public &lt;T&gt; T httpGetPlaceholder(String url, List params, Map headers, Class&lt;T&gt; clazz) &#123; HttpHeaders httpHeaders = new HttpHeaders(); params = params == null ? new ArrayList&lt;&gt;() : params; if (headers != null) &#123; headers.forEach((o1, o2) -&gt; httpHeaders.add(o1.toString(), o2.toString())); &#125; StringBuilder sb = new StringBuilder(url); params.forEach(o2 -&gt; sb.append(\"/\").append(o2)); url = sb.toString().replaceAll(\"&amp;$+|\\\\?$+\", \"\"); ResponseEntity&lt;T&gt; exchange = restTemplate.exchange(url, HttpMethod.GET, new HttpEntity(null, httpHeaders), clazz); return exchange.getBody(); &#125; /** * DELETE请求-?号参数 * * @param url * @param params * @param headers * @return */ public &lt;T&gt; T httpDeleteTraditional(String url, Map params, Map headers, Class&lt;T&gt; clazz) &#123; HttpHeaders httpHeaders = new HttpHeaders(); params = params == null ? new LinkedHashMap&lt;&gt;() : params; if (headers != null) &#123; headers.forEach((o1, o2) -&gt; httpHeaders.add(o1.toString(), o2.toString())); &#125; StringBuilder sb = new StringBuilder(url); sb.append(\"?\"); params.forEach((o1, o2) -&gt; sb.append(o1).append(\"=\").append(o2).append(\"&amp;\")); url = sb.toString().replaceAll(\"&amp;$+|\\\\?$+\", \"\"); ResponseEntity&lt;T&gt; exchange = restTemplate.exchange(url, HttpMethod.DELETE, new HttpEntity(null, httpHeaders), clazz); return exchange.getBody(); &#125; /** * DELETE请求-分隔符参数 * * @param url * @param params * @param headers * @return */ public &lt;T&gt; T httpDeletePlaceholder(String url, List params, Map headers, Class&lt;T&gt; clazz) &#123; HttpHeaders httpHeaders = new HttpHeaders(); params = params == null ? new ArrayList&lt;&gt;() : params; if (headers != null) &#123; headers.forEach((o1, o2) -&gt; httpHeaders.add(o1.toString(), o2.toString())); &#125; StringBuilder sb = new StringBuilder(url); params.forEach(o2 -&gt; sb.append(\"/\").append(o2)); url = sb.toString().replaceAll(\"&amp;$+|\\\\?$+\", \"\"); ResponseEntity&lt;T&gt; exchange = restTemplate.exchange(url, HttpMethod.DELETE, new HttpEntity(null, httpHeaders), clazz); return exchange.getBody(); &#125; /** * PATCH请求-JSON参数 * * @param url * @param params * @param headers * @return */ public &lt;T&gt; T httpPatchJson(String url, Map params, Map headers, Class&lt;T&gt; clazz) &#123; HttpHeaders httpHeaders = new HttpHeaders(); if (headers != null) &#123; headers.forEach((o1, o2) -&gt; httpHeaders.add(o1.toString(), o2.toString())); &#125; // json方式传参 return restTemplate.patchForObject(url, new HttpEntity(params, httpHeaders), clazz); &#125; /** * patch请求-FROM参数 * * @param url * @param params * @param headers * @return */ public &lt;T&gt; T httpPatchForm(String url, Map params, Map headers, Class&lt;T&gt; clazz) &#123; HttpHeaders httpHeaders = new HttpHeaders(); params = params == null ? new LinkedHashMap&lt;&gt;() : params; if (headers != null) &#123; headers.forEach((o1, o2) -&gt; httpHeaders.add(o1.toString(), o2.toString())); &#125; MultiValueMap&lt;String, Object&gt; stringObjectLinkedMultiValueMap = new LinkedMultiValueMap&lt;&gt;(); params.forEach((o1, o2) -&gt; stringObjectLinkedMultiValueMap.add(o1.toString(), o2)); // 表单方式传参 // json方式传参 return restTemplate.patchForObject(url, new HttpEntity(stringObjectLinkedMultiValueMap, httpHeaders), clazz); &#125;&#125; 使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @author Colin.Ye * @version 1.0 * @ClassName LowCreateIndexDemo * @date 2019/3/13 **/@RestController@RequestMapping(\"/lowClient/v1/\")@CrossOrigin@DefaultProperties(defaultFallback = \"defaultFallback\")public class LowCreateIndexDemo extends BaseController &#123; @Autowired private RestTemplateUtils restTemplateUtils; @RequestMapping(\"/index\") @Log @HystrixCommand(commandProperties = @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"2000\")) public String index() &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); // 上传文件 FileSystemResource resource = new FileSystemResource(new File(\"/Users/yezhuang/Documents/data/oracle命令的副本.txt\")); params.put(\"deviceId\", \"123424\"); params.put(\"file\", resource); Object o = restTemplateUtils.httpPostFrom(\"http://localhost:10005/lowClient/v1/test\", params, null, String.class); return o.toString(); &#125; @RequestMapping(\"/test\") public String remoteUpdteTest(String deviceId, @RequestParam MultipartFile file) &#123; System.out.println(deviceId); System.out.println(file.getName()); return \"success\"; &#125; private String fallback() &#123; return \"网络开小差了，请稍后重试···\"; &#125; private String defaultFallback() &#123; return \"defaultFallback: 网络开小差了，请稍后重试···\"; &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://zhuangyea.github.io/tags/java/"}]},{"title":"java 远程执行Shell命令-通过Jsch连接","slug":"java/java 远程执行Shell命令-通过Jsch连接","date":"2019-05-10T13:20:00.000Z","updated":"2019-06-26T05:50:54.309Z","comments":true,"path":"2019/05/10/java/java 远程执行Shell命令-通过Jsch连接/","link":"","permalink":"http://zhuangyea.github.io/2019/05/10/java/java 远程执行Shell命令-通过Jsch连接/","excerpt":"","text":"JSch是Java Secure Channel的缩写。JSch是一个SSH2的纯Java实现。它允许你连接到一个SSH服务器，并且可以使用端口转发，X11转发，文件传输等，当然你也可以集成它的功能到你自己的应用程序。 本文只介绍如何使用JSch实现的SFTP功能。 SFTP是Secure File Transfer Protocol的缩写，安全文件传送协议。可以为传输文件提供一种安全的加密方法。SFTP 为 SSH的一部份，是一种传输文件到服务器的安全方式。SFTP是使用加密传输认证信息和传输的数据，所以，使用SFTP是非常安全的。但是，由于这种传输方式使用了加密/解密技术，所以传输效率比普通的FTP要低得多，如果您对网络安全性要求更高时，可以使用SFTP代替FTP。（来自百度的解释） 要使用JSch，需要下载它的jar包，请从官网下载它：http://www.jcraft.com/jsch/ ChannelSftp类是JSch实现SFTP核心类，它包含了所有SFTP的方法，如：put()： 文件上传get()： 文件下载cd()： 进入指定目录ls()： 得到指定目录下的文件列表rename()： 重命名指定文件或目录rm()： 删除指定文件mkdir()： 创建目录rmdir()： 删除目录 等等（这里省略了方法的参数，put和get都有多个重载方法，具体请看源代码，这里不一一列出。）JSch支持三种文件传输模式： 传输模式名描述OVERWRITE完全覆盖模式，这是JSch的默认文件传输模式，即如果目标文件已经存在，传输的文件将完全覆盖目标文件，产生新的文件。RESUME恢复模式，如果文件已经传输一部分，这时由于网络或其他任何原因导致文件传输中断，如果下一次传输相同的文件，则会从上一次中断的地方续传。APPEND追加模式，如果目标文件已存在，传输的文件将在目标文件后追加。 1.引入jar包 12345&lt;dependency&gt; &lt;groupId&gt;com.jcraft&lt;/groupId&gt; &lt;artifactId&gt;jsch&lt;/artifactId&gt; &lt;version&gt;0.1.54&lt;/version&gt; &lt;/dependency&gt; 2.实际例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291package com.bluemoon.executor.core.executor;import com.bluemoon.executor.core.log.XxlJobLogger;import com.jcraft.jsch.*;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.*;import java.nio.charset.Charset;public class JSchExecutor &#123; private static Logger log = LoggerFactory.getLogger(JSchExecutor.class); private String charset = \"UTF-8\"; // 设置编码格式 private String user; // 用户名 private String passwd; // 登录密码 private String host; // 主机IP private int port = 22; //默认端口 private JSch jsch; private Session session; private ChannelSftp sftp; /** * * @param user 用户名 * @param passwd 密码 * @param host 主机IP */ public JSchExecutor(String user, String passwd, String host ) &#123; this.user = user; this.passwd = passwd; this.host = host; &#125; /** * * @param user 用户名 * @param passwd 密码 * @param host 主机IP */ public JSchExecutor(String user, String passwd, String host , int port ) &#123; this.user = user; this.passwd = passwd; this.host = host; this.port = port; &#125; /** * 连接到指定的IP * * @throws JSchException */ public void connect() throws JSchException &#123; jsch = new JSch(); session = jsch.getSession(user, host, port); session.setPassword(passwd); java.util.Properties config = new java.util.Properties(); config.put(\"StrictHostKeyChecking\", \"no\"); session.setConfig(config); session.connect(); Channel channel = session.openChannel(\"sftp\"); channel.connect(); sftp = (ChannelSftp) channel; log.info(\"连接到SFTP成功。host: \" + host); &#125; /** * 关闭连接 */ public void disconnect()&#123; if (sftp != null &amp;&amp; sftp.isConnected()) &#123; sftp.disconnect(); &#125; if(session != null &amp;&amp; session.isConnected())&#123; session.disconnect(); &#125; &#125; /** * 执行一条命令 */ public int execCmd(String command) throws Exception&#123; XxlJobLogger.log( \"开始执行命令:\" + command); int returnCode = -1; BufferedReader reader = null; Channel channel = null; channel = session.openChannel(\"exec\"); ((ChannelExec) channel).setCommand(command); channel.setInputStream(null); ((ChannelExec) channel).setErrStream(System.err); InputStream in = channel.getInputStream(); reader = new BufferedReader(new InputStreamReader(in));//中文乱码貌似这里不能控制，看连接的服务器的 channel.connect(); System.out.println(\"The remote command is: \" + command); String buf ; while ((buf = reader.readLine()) != null) &#123; XxlJobLogger.log(buf); &#125; reader.close(); // Get the return code only after the channel is closed. if (channel.isClosed()) &#123; returnCode = channel.getExitStatus(); &#125; XxlJobLogger.log( \"Exit-status:\" + returnCode ); /* StringBuffer buf = new StringBuffer( 1024 ); byte[] tmp = new byte[ 1024 ]; while ( true ) &#123; while ( in.available() &gt; 0 ) &#123; int i = in.read( tmp, 0, 1024 ); if ( i &lt; 0 ) break; buf.append( new String( tmp, 0, i ) ); &#125; if ( channel.isClosed() ) &#123; res = channel.getExitStatus(); XxlJobLogger.log( \"Exit-status:\" + res ); System.out.println( \"Exit-status:\" + res ); break; &#125; TimeUnit.MILLISECONDS.sleep(100); &#125; XxlJobLogger.log( buf.toString() );*/ channel.disconnect(); return returnCode; &#125; /** * 执行相关的命令 */ public void execCmd() &#123; BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); String command = \"\"; BufferedReader reader = null; Channel channel = null; try &#123; while ((command = br.readLine()) != null) &#123; channel = session.openChannel(\"exec\"); ((ChannelExec) channel).setCommand(command); channel.setInputStream(null); ((ChannelExec) channel).setErrStream(System.err); channel.connect(); InputStream in = channel.getInputStream(); reader = new BufferedReader(new InputStreamReader(in, Charset.forName(charset))); String buf = null; while ((buf = reader.readLine()) != null) &#123; System.out.println(buf); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (JSchException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; reader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; channel.disconnect(); &#125; &#125; /** * 上传文件 */ public void uploadFile(String local,String remote) throws Exception &#123; File file = new File(local); if (file.isDirectory()) &#123; throw new RuntimeException(local + \" is not a file\"); &#125; InputStream inputStream = null; try &#123; String rpath = remote.substring(0,remote.lastIndexOf(\"/\")+1); if (!isDirExist(rpath))&#123; createDir(rpath); &#125; inputStream = new FileInputStream(file); sftp.setInputStream(inputStream); sftp.put(inputStream, remote); &#125; catch (Exception e) &#123; throw e; &#125;finally&#123; if(inputStream != null)&#123; inputStream.close(); &#125; &#125; &#125; /** * 下载文件 */ public void downloadFile(String remote,String local) throws Exception&#123; OutputStream outputStream = null; try &#123; sftp.connect(5000); outputStream = new FileOutputStream(new File(local)); sftp.get(remote, outputStream); outputStream.flush(); &#125; catch (Exception e) &#123; throw e; &#125;finally&#123; if(outputStream != null)&#123; outputStream.close(); &#125; &#125; &#125; /** * 移动到相应的目录下 * @param pathName 要移动的目录 * @return */ public boolean changeDir(String pathName)&#123; if(pathName == null || pathName.trim().equals(\"\"))&#123; log.debug(\"invalid pathName\"); return false; &#125; try &#123; sftp.cd(pathName.replaceAll(\"\\\\\\\\\", \"/\")); log.debug(\"directory successfully changed,current dir=\" + sftp.pwd()); return true; &#125; catch (SftpException e) &#123; log.error(\"failed to change directory\",e); return false; &#125; &#125; /** * 创建一个文件目录，mkdir每次只能创建一个文件目录 * 或者可以使用命令mkdir -p 来创建多个文件目录 */ public void createDir(String createpath) &#123; try &#123; if (isDirExist(createpath)) &#123; sftp.cd(createpath); return; &#125; String pathArry[] = createpath.split(\"/\"); StringBuffer filePath = new StringBuffer(\"/\"); for (String path : pathArry) &#123; if (path.equals(\"\")) &#123; continue; &#125; filePath.append(path + \"/\"); if (isDirExist(filePath.toString())) &#123; sftp.cd(filePath.toString()); &#125; else &#123; // 建立目录 sftp.mkdir(filePath.toString()); // 进入并设置为当前目录 sftp.cd(filePath.toString()); &#125; &#125; sftp.cd(createpath); &#125; catch (SftpException e) &#123; throw new RuntimeException(\"创建路径错误：\" + createpath); &#125; &#125; /** * 判断目录是否存在 * @param directory * @return */ public boolean isDirExist(String directory) &#123; boolean isDirExistFlag = false; try &#123; SftpATTRS sftpATTRS = sftp.lstat(directory); isDirExistFlag = true; return sftpATTRS.isDir(); &#125; catch (Exception e) &#123; if (e.getMessage().toLowerCase().equals(\"no such file\")) &#123; isDirExistFlag = false; &#125; &#125; return isDirExistFlag; &#125; &#125; 3.用法 123456789101112131415public static void main(String[] args) &#123; JSchExecutor jSchUtil = new JSchExecutor( \"user\", \"password#\",\"192.168.243.21\"); try &#123; jSchUtil.connect(); jSchUtil.uploadFile(\"C:\\\\data\\\\applogs\\\\bd-job\\\\jobhandler\\\\2020-03-07\\\\employee.py\",\"/data/applogs/bd-job-777/jobhandler/2018-09-15/employee.py\"); //jSchUtil.execCmd(\"python /data/bluemoon/kettle/runScript/ods/fact_org_employee.py 'so you is wahek 哈哈哈快递放假塑料袋放进了'\"); jSchUtil.execCmd(\"python /data/applogs/bd-job/jobhandler/gluesource/employee.py 中文名称\"); //jSchUtil.execCmd(\"cat /data/applogs/bd-job/jobhandler/test\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; jSchUtil.disconnect(); &#125;&#125; 4.实时返回打印的日志在实际开发中，需要执行一个python文档，里面含有多条的python语句，可能耗时1个小时才能执行完，这种情况需要能够实时的返回日志信息，看看python到底执行到哪一步。 使用ChannelShell可与服务器保持连接状态，可交互信息 用法： 123456789101112131415161718192021222324252627282930313233343536/** * 实时打印日志信息 */public int shellCmd(String command) throws Exception&#123; XxlJobLogger.log( \"开始执行命令:\" + command); int returnCode = -1; ChannelShell channel=(ChannelShell) session.openChannel(\"shell\"); InputStream in = channel.getInputStream(); channel.setPty(true); channel.connect(); OutputStream os = channel.getOutputStream(); os.write((command + \"\\r\\n\").getBytes()); os.write(\"exit\\r\\n\".getBytes()); os.flush(); XxlJobLogger.log(\"The remote command is:&#123;&#125;\" ,command); byte[] tmp=new byte[1024]; while(true) &#123; while (in.available() &gt; 0) &#123; int i = in.read(tmp, 0, 1024); if (i &lt; 0) break; XxlJobLogger.log(new String(tmp, 0, i)); &#125; if (channel.isClosed()) &#123; if (in.available() &gt; 0) continue; returnCode = channel.getExitStatus(); XxlJobLogger.log(\"exit-status: \" + channel.getExitStatus()); break; &#125; try&#123;Thread.sleep(1000);&#125;catch(Exception ee)&#123;&#125; &#125; os.close(); in.close(); channel.disconnect(); session.disconnect(); return returnCode;&#125; 复制原文章（防止原文丢失）(如果涉及侵权，请联系作者进行删除、修改):java 远程执行Shell命令-通过Jsch连接;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://zhuangyea.github.io/tags/java/"}]},{"title":"sqoop导入导出Mysql","slug":"hadoop/sqoop导入导出Mysql","date":"2019-05-06T07:00:00.000Z","updated":"2019-05-06T08:17:22.159Z","comments":true,"path":"2019/05/06/hadoop/sqoop导入导出Mysql/","link":"","permalink":"http://zhuangyea.github.io/2019/05/06/hadoop/sqoop导入导出Mysql/","excerpt":"","text":"hive命令 12345678910111213141516171819202122show databases; # 查看某个数据库use 数据库; # 进入某个数据库show tables; # 展示所有表desc 表名; # 显示表结构show partitions 表名; # 显示表名的分区show create table_name; # 显示创建表的结构truncate table 表名; #表名;仅删除表中数据，保留表结构drop table 表名; #删除表// 创建hive表create table travel_config_spider( id int ,pid int ,province string ,city string ,scenic_spot string ,url string ,url_params string)row format delimitedfields terminated by &apos;\\t&apos;; 用sqoop将mysql的数据导入到hive表中 123456789101112131415161718192021222324sqoop import \\--connect &apos;jdbc:mysql://ip:port/data_acquisition?useUnicode=true&amp;characterEncoding=utf-8&apos; \\--username root \\--password 123456 \\--table travel_config_spider \\--columns id,pid,province,city,scenic_spot,url,url_params \\--fields-terminated-by &quot;\\t&quot; \\--hive-import \\--hive-table colinhive.travel_config_spider \\--target-dir /tmp/colinhive/ \\;// 另一种参数sqoop import \\--connect &apos;jdbc:mysql://ip:port/data_acquisition?useUnicode=true&amp;characterEncoding=utf-8&apos; \\--username root \\--password 123456 \\--query &quot;SELECT id,pid,province,city,scenic_spot,url,url_params from travel_config_spider where 1=1 and \\$CONDITIONS&quot; \\--split-by id --columns id,pid,province,city,scenic_spot,url,url_params \\--hive-import \\--fields-terminated-by &quot;\\t&quot; \\--hive-table colinhive.travel_config_spider \\--target-dir /tmp/colinhive/ \\; 用sqoop将hive的数据导入到mysql表中 123456789sqoop export \\--connect &apos;jdbc:mysql://ip:port/data_acquisition?useUnicode=true&amp;characterEncoding=utf-8&apos; \\--username root \\--password 123456 \\--table newtab \\--export-dir /opt/hive/warehouse/colinhive.db/newtab \\--columns id,source_name1,url1,url2,url_params2 \\--input-fields-terminated-by &apos;\\t&apos;;","categories":[],"tags":[{"name":"sqoop","slug":"sqoop","permalink":"http://zhuangyea.github.io/tags/sqoop/"},{"name":"hive","slug":"hive","permalink":"http://zhuangyea.github.io/tags/hive/"}]},{"title":"通过IDEA连接Hive数据库","slug":"idea/使用IDEA Database Tool连接Hive数据库","date":"2019-05-06T07:00:00.000Z","updated":"2019-08-22T07:51:30.643Z","comments":true,"path":"2019/05/06/idea/使用IDEA Database Tool连接Hive数据库/","link":"","permalink":"http://zhuangyea.github.io/2019/05/06/idea/使用IDEA Database Tool连接Hive数据库/","excerpt":"","text":"版本介绍： 12Idea: 2018.1hive: 1.6 步骤如下： 打开Database 因为IDEA没有内置hive的驱动，所以需要自己新建一个Driver，如下图： 2.1 先打开Database工具，选择Database Source Properties 2.2 选择新建Driver 2.3 选择后自动跳转出现新建Driver配置页面 修改Name名字（命名驱动的名字，此处我命名为HIVE2） 点击+，添加hive相关驱动jar包,点击下载【hive-lib】 2.4 如果hive版本是最新版本可以根据下图操作 效果演示 借鉴文章如下(如果涉及侵权，请联系作者进行删除、修改):使用IDEA Database Tool连接Hive数据库","categories":[],"tags":[{"name":"idea","slug":"idea","permalink":"http://zhuangyea.github.io/tags/idea/"}]},{"title":"UnitTest单元测试","slug":"java/UnitTest单元测试","date":"2019-04-24T03:20:00.000Z","updated":"2020-04-28T11:14:14.570Z","comments":true,"path":"2019/04/24/java/UnitTest单元测试/","link":"","permalink":"http://zhuangyea.github.io/2019/04/24/java/UnitTest单元测试/","excerpt":"","text":"unitTestBase类，其他test类集成Base类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132import com.alibaba.fastjson.JSONObject;import com.isstech.cay.model.result.ResultCode;import com.isstech.cay.utils.AssertUtil;import org.junit.After;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.http.MediaType;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import org.springframework.web.context.WebApplicationContext;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.delete;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.post;import static org.springframework.test.web.servlet.result.MockMvcResultHandlers.print;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;@RunWith(SpringRunner.class)@SpringBootTestpublic class AnalysisApplicationTests &#123; protected MockMvc mockMvc; @Autowired protected WebApplicationContext wac; @Before public void init() &#123; System.out.println(\"开始测试-----------------\"); mockMvc = MockMvcBuilders.webAppContextSetup(wac).build(); //初始化MockMvc对象 &#125; @Test public void test() &#123; &#125; @After public void after() &#123; System.out.println(\"测试结束-----------------\"); &#125; /** * 添加 * * @param url * @param entity * @throws Exception */ public JSONObject testAdd(String url, Object entity) throws Exception &#123; String requestJson = JSONObject.toJSONString(entity); String responseString = mockMvc.perform(post(url) .contentType(MediaType.APPLICATION_JSON).content(requestJson)).andDo(print()) .andExpect(status().isOk()).andReturn().getResponse().getContentAsString(); JSONObject jsonObject = JSONObject.parseObject(responseString); AssertUtil.isTrue(ResultCode.SUCCESS.code().equals(jsonObject.getInteger(\"status\")), \"添加失败！\"); System.out.println(jsonObject.toJSONString()); return jsonObject; &#125; /** * 修改 * * @param url * @param entity * @throws Exception */ public JSONObject testUpdate(String url, Object entity) throws Exception &#123; String requestJson = JSONObject.toJSONString(entity); String responseString = mockMvc.perform(post(url) .contentType(MediaType.APPLICATION_JSON).content(requestJson)).andDo(print()) .andExpect(status().isOk()).andReturn().getResponse().getContentAsString(); JSONObject jsonObject = JSONObject.parseObject(responseString); AssertUtil.isTrue(ResultCode.SUCCESS.code().equals(jsonObject.getInteger(\"status\")), \"修改失败！\"); System.out.println(jsonObject.toJSONString()); return jsonObject; &#125; /** * 删除 * * @param url 删除地址 * @throws Exception */ public JSONObject testDel(String url) throws Exception &#123; String responseString = mockMvc.perform(delete(url) .contentType(MediaType.APPLICATION_JSON)).andDo(print()) .andExpect(status().isOk()).andReturn().getResponse().getContentAsString(); JSONObject jsonObject = JSONObject.parseObject(responseString); AssertUtil.isTrue(ResultCode.SUCCESS.code().equals(jsonObject.getInteger(\"status\")), \"删除失败！\"); System.out.println(jsonObject.toJSONString()); return jsonObject; &#125; /** * 查询 * * @param url * @return * @throws Exception */ public JSONObject testGet(String url) throws Exception &#123; String responseString = mockMvc.perform(get(url)).andDo(print()) .andExpect(status().isOk()).andReturn().getResponse().getContentAsString(); JSONObject jsonObject = JSONObject.parseObject(responseString); AssertUtil.isTrue(ResultCode.SUCCESS.code().equals(jsonObject.getInteger(\"status\")), \"GET查询失败！\"); return jsonObject; &#125; /** * 查询 * * @param url * @return * @throws Exception */ public JSONObject testPost(String url, Object entity) throws Exception &#123; String requestJson = JSONObject.toJSONString(entity); String responseString = mockMvc.perform(post(url) .contentType(MediaType.APPLICATION_JSON).content(requestJson)).andDo(print()) .andExpect(status().isOk()).andReturn().getResponse().getContentAsString(); JSONObject jsonObject = JSONObject.parseObject(responseString); AssertUtil.isTrue(ResultCode.SUCCESS.code().equals(jsonObject.getInteger(\"status\")), \"POST查询失败！\"); System.out.println(jsonObject.toJSONString()); return jsonObject; &#125;&#125; api接口测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import com.isstech.cay.model.BpSysNotice;import com.isstech.cay.model.BpTodo;import org.junit.Test;/** * 待办事项管理 * * @author Colin.Ye * @version 1.0 * @ClassName BpSysTodoTests * @date 2020/4/13 **/public class BpSysTodoTests extends AnalysisApplicationTests &#123; private static final String REST = \"/bp/todo/\"; /** * 新增通知 */ @Test @Transactional @Rollback public void add() throws Exception &#123; super.testAdd(REST + \"add\", new BpTodo() &#123;&#123; // setId(\"5630e9f55cd94e8b878c6f4d672191ad\"); setTitle(\"测试待办事项\"); setSysId(\"系统ID\"); setTodoType(\"待办事项类型\"); setSysUrl(\"系统URL\"); setCreatorId(\"createId\"); setUpdateId(\"updateId\"); &#125;&#125;); &#125; /** * 修改通知 */ @Test @Transactional @Rollback public void update() throws Exception &#123; super.testUpdate(REST + \"update\", new BpTodo() &#123;&#123; setId(\"5630e9f55cd94e8b878c6f4d672191ad\"); setTitle(\"测试待办事项1\"); setSysId(\"系统ID1\"); setTodoType(\"待办事项类型1\"); setSysUrl(\"系统URL1\"); setCreatorId(\"createId1\"); setUpdateId(\"updateId1\"); &#125;&#125;); &#125; /** * 删除通知 * * @throws Exception */ @Test @Transactional @Rollback public void del() throws Exception &#123; String id = \"5630e9f55cd94e8b878c6f4d672191ad\"; super.testDel(REST + \"delete/\" + id); &#125; /** * 根据ID查询通知信息 * * @throws Exception */ @Test public void get() throws Exception &#123; String id = \"5630e9f55cd94e8b878c6f4d672191ad\"; super.testGet(REST + \"get/\" + id); &#125; /** * 条件查询应用 * * @throws Exception */ @Test public void fetchAppList() throws Exception &#123; super.testPost(REST + \"list\", new BpTodo() &#123;&#123; setTitle(\"测试待办事项\"); setSysId(\"系统ID\"); setTodoType(\"待办事项类型\"); setSysUrl(\"系统URL\"); setCreatorId(\"createId\"); setUpdateId(\"updateId\"); &#125;&#125;); &#125; /** * 条件查询应用-分页 * * @throws Exception */ @Test public void fetchAppListPage() throws Exception &#123; super.testPost(REST + \"list/page\", new BpSysNotice() &#123;&#123; setCurrentPage(1); setPageSize(2); &#125;&#125;); &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://zhuangyea.github.io/tags/java/"}]},{"title":"多数据源切换.md","slug":"java/多数据源切换","date":"2019-04-24T03:20:00.000Z","updated":"2019-08-22T07:32:09.305Z","comments":true,"path":"2019/04/24/java/多数据源切换/","link":"","permalink":"http://zhuangyea.github.io/2019/04/24/java/多数据源切换/","excerpt":"","text":"初始化、添加、切换数据源 1234567891011121314151617181920212223// 初始化默认MYSQL连接MysqlDataSourceUtil.getInstance().initDataSource();// 初始化默认HIVE连接HiveDataSourceUtil.getInstance().initDataSource();// 初始化其他MYSQL连接sourceService service = (sourceService) SpringContextUtil.getBean(\"sourceService\");List&lt;AnalysisDataSource&gt; data = service.selectAll();if (data != null &amp;&amp; data.size() != 0) &#123; logger.info(\"开始初始化数据源......\"); for (AnalysisDataSource source : data) &#123; MysqlDataSourceUtil.getInstance().initOthersDataSource(source); logger.info(\"初始化数据源:(\" + source.getId() + \")完毕......\"); &#125; MysqlDataSourceUtil.getInstance().flushDataSource();&#125; else &#123; logger.info(\"数据源暂无配置......\");&#125;logger.info(\"==============springboot启动成功=================\");//切换数据源HiveDataSourceUtil.getInstance().setDataSource(hiveKey);MysqlDataSourceUtil.getInstance().setDataSource(dbkey); 以下为实现代码： HIVE连接池配置(HiveDruidConfig.java) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.isoftstone.ismart.analysis.config;import com.alibaba.druid.pool.DruidDataSource;import com.isoftstone.ismart.analysis.util.datasoruce.HiveDataSourceUtil;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.core.JdbcTemplate;import javax.sql.DataSource;import java.util.HashMap;import java.util.Map;/** * HIVE连接池配置 * * @author Colin.Ye * @version 1.0 * @ClassName HiveDruidConfig * @date 2019/4/22 **/@Configuration@ConfigurationProperties(prefix = \"hive\")public class HiveDruidConfig &#123; private static final Logger logger = LoggerFactory.getLogger(HiveDruidConfig.class); private String url; private String user; private String password; private String driverClassName; private int initialSize; private int minIdle; private int maxActive; private int maxWait; private int timeBetweenEvictionRunsMillis; private int minEvictableIdleTimeMillis; private String validationQuery; private boolean testWhileIdle; private boolean testOnBorrow; private boolean testOnReturn; private boolean poolPreparedStatements; private int maxPoolPreparedStatementPerConnectionSize; @Bean(name = \"hiveDruidDataSource\") @Qualifier(\"hiveDruidDataSource\") public DataSource hiveDruidDataSource() &#123; DruidDataSource datasource = new DruidDataSource(); datasource.setUrl(url); datasource.setUsername(user); datasource.setPassword(password); datasource.setDriverClassName(driverClassName); // pool configuration datasource.setInitialSize(initialSize); datasource.setMinIdle(minIdle); datasource.setMaxActive(maxActive); datasource.setMaxWait(maxWait); datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); datasource.setValidationQuery(validationQuery); datasource.setTestWhileIdle(testWhileIdle); datasource.setTestOnBorrow(testOnBorrow); datasource.setTestOnReturn(testOnReturn); datasource.setPoolPreparedStatements(poolPreparedStatements); datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); logger.debug(\"Hive DataSource Inject Successfully...\"); return datasource; &#125; @Bean(name = \"hiveDynamicDataSource\") public DataSource hiveDynamicDataSource() &#123; HiveDataSourceUtil myDynamicDataSource = HiveDataSourceUtil.getInstance(); // 配置多数据源 Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); targetDataSources.put(\"master\", hiveDruidDataSource()); myDynamicDataSource.setTargetDataSources(targetDataSources); //设置默认数据源，在动态添加数据源的时候，就可以不再添加此数据源了 myDynamicDataSource.setDefaultTargetDataSource(hiveDruidDataSource()); return myDynamicDataSource; &#125; // 此处省略各个属性的get和set方法 @Bean(name = \"hiveDruidTemplate\") public JdbcTemplate hiveDruidTemplate(@Qualifier(\"hiveDynamicDataSource\") DataSource dataSource) &#123; return new JdbcTemplate(dataSource); &#125;&#125; MySql连接池配置(Config.java) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package com.isoftstone.ismart.analysis.config;import com.alibaba.druid.pool.DruidDataSource;import com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceBuilder;import com.alibaba.druid.support.http.StatViewServlet;import com.alibaba.druid.support.http.WebStatFilter;import com.github.pagehelper.PageHelper;import com.isoftstone.ismart.analysis.filter.SwitchDBFilter;import com.isoftstone.ismart.analysis.filter.analysisFilter;import com.isoftstone.ismart.analysis.util.datasoruce.MysqlDataSourceUtil;import com.mchange.v2.c3p0.ComboPooledDataSource;import org.apache.ibatis.plugin.Interceptor;import org.mybatis.spring.SqlSessionFactoryBean;import org.slf4j.Logger;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.boot.web.servlet.ServletRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import org.springframework.transaction.PlatformTransactionManager;import javax.sql.DataSource;import java.beans.PropertyVetoException;import java.util.HashMap;import java.util.Map;import java.util.Properties;@Configurationpublic class Config &#123; private final Logger logger = org.slf4j.LoggerFactory.getLogger(Config.class); /** * @return * @Bean 防止数据监控报错，无法查看数据源 * @ConfigurationProperties 会把配置文件的参数自动赋值到dataSource里。 * @Primary 用于标识默认使用的 DataSource Bean */ @Bean(destroyMethod = \"close\", initMethod = \"init\", name = \"masterDataSource\") @ConfigurationProperties(prefix = \"spring.datasource\") @Primary public DataSource masterDataSource() &#123; logger.info(\"创建masterDataSource\"); DruidDataSource druidDataSource = DruidDataSourceBuilder.create().build(); return druidDataSource; &#125; @Bean(name = \"dynamicDataSource\") public DataSource dynamicDataSource() &#123; MysqlDataSourceUtil myDynamicDataSource = MysqlDataSourceUtil.getInstance(); // 配置多数据源 Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); targetDataSources.put(\"master\", masterDataSource()); myDynamicDataSource.setTargetDataSources(targetDataSources); //设置默认数据源，在动态添加数据源的时候，就可以不再添加此数据源了 myDynamicDataSource.setDefaultTargetDataSource(masterDataSource()); return myDynamicDataSource; &#125; /** * 配置 SqlSessionFactoryBean */ @Bean(value = \"sqlSessionFactoryBean222\") @ConfigurationProperties(prefix = \"mybatis\") public SqlSessionFactoryBean sqlSessionFactoryBean() &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); // 配置数据源，此处配置为关键配置，如果没有将 dynamicDataSource 作为数据源则不能实现切换 sqlSessionFactoryBean.setDataSource(dynamicDataSource()); sqlSessionFactoryBean.setPlugins(new Interceptor[]&#123;pageHelper()&#125;); return sqlSessionFactoryBean; &#125; /** * 注入 DataSourceTransactionManager 用于事务管理 */ @Bean public PlatformTransactionManager transactionManager() &#123; return new DataSourceTransactionManager(dynamicDataSource()); &#125; /** * druid过滤器 * * @return */ @Bean public FilterRegistrationBean statFilter() &#123; //创建过滤器 FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(new WebStatFilter()); //设置过滤器过滤路径 filterRegistrationBean.addUrlPatterns(\"/*\"); //忽略过滤的形式 filterRegistrationBean.addInitParameter(\"exclusions\", \"*.js,*.gif,*.png,*.css,*.ico,/druid/*\"); return filterRegistrationBean; &#125;// @Bean public Interceptor pageHelper() &#123; //分页插件 PageHelper pageHelper = new PageHelper(); Properties properties = new Properties(); properties.setProperty(\"reasonable\", \"true\"); properties.setProperty(\"dialect\", \"mysql\"); //RowBounds参数offset作为PageNum使用 - 默认不使用 properties.setProperty(\"offsetAsPageNum\", \"true\"); //RowBounds是否进行count查询 - 默认不查询 properties.setProperty(\"rowBoundsWithCount\", \"true\"); //当设置为true的时候，如果pagesize设置为0（或RowBounds的limit=0），就不执行分页，返回全部结果 properties.setProperty(\"pageSizeZero\", \"true\"); //分页合理化 properties.setProperty(\"reasonable\", \"true\"); //是否支持接口参数来传递分页参数，默认false properties.setProperty(\"supportMethodsArguments\", \"true\"); properties.setProperty(\"returnPageInfo\", \"check\"); properties.setProperty(\"params\", \"count=countSql\"); properties.setProperty(\"params\", \"pageNum=page;pageSize=rows;orderBy=orderBy\"); pageHelper.setProperties(properties); return pageHelper; &#125;&#125; AnalysisDataSource.java12345678910111213141516171819202122232425262728293031323334package com.isoftstone.ismart.analysis.entity;import com.alibaba.druid.pool.DruidDataSource;import java.io.Serializable;import java.util.Date;public class AnalysisDataSource implements Serializable &#123; private static final long serialVersionUID = 1L; private String id; private String url; private String username; private String password; private Byte sourcetype; private Date createtime; private Date updatetime; private Byte sourcestatus; private String version; private DruidDataSource druidDataSource; // 此处省略各个属性的get和set方法&#125; 多数据源切换工具抽象类(BaseDataSource.java)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.isoftstone.ismart.analysis.util.datasoruce;import com.alibaba.druid.pool.DruidDataSource;import com.isoftstone.ismart.analysis.entity.AnalysisDataSource;import com.isoftstone.ismart.analysis.util.SpringContextUtil;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;import java.util.HashMap;import java.util.Map;/** * 多数据源切换工具抽象类 * * @author Colin.Ye * @version 1.0 * @ClassName BaseDataSource * @date 2019/4/23 **/public abstract class BaseDataSource extends AbstractRoutingDataSource &#123; private final Logger log = LoggerFactory.getLogger(BaseDataSource.class); protected final Map&lt;Object, Object&gt; dataSourceMap = new HashMap&lt;&gt;(); // 对当前线程的操作-线程安全的 private final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;String&gt;(); public final ThreadLocal&lt;String&gt; key = new ThreadLocal&lt;String&gt;(); // 调用此方法，切换数据源 public void setDataSource(String dataSource) &#123; if (dataSourceMap.containsKey(dataSource)) &#123; contextHolder.set(dataSource); key.set(dataSource); &#125; else &#123; throw new RuntimeException(\"数据源:\" + dataSource + \"不存在\"); &#125; &#125; // 获取数据源 public String getDataSource() &#123; return contextHolder.get(); &#125; // 删除数据源 public void clearDataSource() &#123; contextHolder.remove(); &#125; /** * 初始化默认数据源-抽象类 */ protected abstract void initDataSource(); /** * 初始化默认数据源 * * @param springBeanId */ protected void initDataSource(String springBeanId) &#123; //获取masterDataSource DruidDataSource masterDataSource = (DruidDataSource) SpringContextUtil.getBean(springBeanId); addDataSource(\"master\", masterDataSource); &#125; /** * 加载数据源-抽象类 */ protected abstract void flushDataSource(); /** * 添加数据源 * * @param key * @param masterDataSource */ protected void addDataSource(String key, DruidDataSource masterDataSource) &#123; dataSourceMap.put(key, masterDataSource); &#125; /** * 初始化其他数据源 * * @param analysisDataSource */ protected abstract void initOthersDataSource(AnalysisDataSource analysisDataSource);&#125; HIVE多数据源切换工具类(HiveDataSourceUtil.java)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package com.isoftstone.ismart.analysis.util.datasoruce;import com.isoftstone.ismart.analysis.entity.AnalysisDataSource;import com.isoftstone.ismart.analysis.util.SpringContextUtil;import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * HIVE多数据源切换工具类 * * @author Colin.Ye * @version 1.0 * @ClassName HiveDataSourceUtil * @date 2019/4/23 **/public class HiveDataSourceUtil extends BaseDataSource &#123; private final Logger log = LoggerFactory.getLogger(HiveDataSourceUtil.class); private static class HiveDataSourceInstance &#123; private static final HiveDataSourceUtil INSTANCE = new HiveDataSourceUtil(); &#125; public static HiveDataSourceUtil getInstance() &#123; return HiveDataSourceInstance.INSTANCE; &#125; /** * 初始化默认数据源 */ @Override public void initDataSource() &#123; //获取masterDataSource super.initDataSource(\"hiveDruidDataSource\"); //刷新数据源 flushDataSource(); &#125; /** * 加载数据源 */ @Override public void flushDataSource() &#123; //获取spring管理的dynamicDataSource HiveDataSourceUtil myDynamicDataSource = (HiveDataSourceUtil) SpringContextUtil.getBean(\"hiveDynamicDataSource\"); //将数据源设置到 targetDataSources myDynamicDataSource.setTargetDataSources(dataSourceMap); //将 targetDataSources 中的连接信息放入 resolvedDataSources 管理 myDynamicDataSource.afterPropertiesSet(); &#125; /** * 初始化其他数据源 * * @param analysisDataSource */ @Override public void initOthersDataSource(AnalysisDataSource analysisDataSource) &#123; if (analysisDataSource == null || StringUtils.isBlank(analysisDataSource.getId())) &#123; return; &#125; // pool configuration// datasource.setInitialSize(initialSize);// datasource.setMinIdle(minIdle);// datasource.setMaxActive(maxActive);// datasource.setMaxWait(maxWait);// datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis);// datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis);// datasource.setValidationQuery(validationQuery);// datasource.setTestWhileIdle(testWhileIdle);// datasource.setTestOnBorrow(testOnBorrow);// datasource.setTestOnReturn(testOnReturn);// datasource.setPoolPreparedStatements(poolPreparedStatements);// datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); //添加数据源到map addDataSource(analysisDataSource.getId(), analysisDataSource.getDruidDataSource()); &#125; @Override protected Object determineCurrentLookupKey() &#123; //获取当前线程的数据源，如果不存在使用master数据源 String datasource = getDataSource(); if (StringUtils.isBlank(datasource)) &#123; datasource = \"master\"; &#125; logger.info(\"hive-datasource=\" + datasource); return datasource; &#125;&#125; MYSQL多数据源切换工具类(MysqlDataSourceUtil.java)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package com.isoftstone.ismart.analysis.util.datasoruce;import com.alibaba.druid.pool.DruidDataSource;import com.isoftstone.ismart.analysis.config.Config;import com.isoftstone.ismart.analysis.entity.AnalysisDataSource;import com.isoftstone.ismart.analysis.util.SpringContextUtil;import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.sql.Connection;import java.sql.SQLException;/** * MYSQL多数据源切换工具类 * * @author Colin.Ye * @version 1.0 * @ClassName MysqlDataSourceUtil * @date 2019/4/23 **/public class MysqlDataSourceUtil extends BaseDataSource &#123; private final Logger log = LoggerFactory.getLogger(HiveDataSourceUtil.class); private static class MysqlDataSourceInstance &#123; private static final MysqlDataSourceUtil INSTANCE = new MysqlDataSourceUtil(); &#125; public static MysqlDataSourceUtil getInstance() &#123; return MysqlDataSourceInstance.INSTANCE; &#125; /** * 初始化默认数据源 */ @Override public void initDataSource() &#123; //获取masterDataSource super.initDataSource(\"masterDataSource\"); //刷新数据源 flushDataSource(); &#125; /** * 加载数据源 */ @Override public void flushDataSource() &#123; //获取spring管理的dynamicDataSource MysqlDataSourceUtil myDynamicDataSource = (MysqlDataSourceUtil) SpringContextUtil.getBean(\"dynamicDataSource\"); //将数据源设置到 targetDataSources myDynamicDataSource.setTargetDataSources(dataSourceMap); //将 targetDataSources 中的连接信息放入 resolvedDataSources 管理 myDynamicDataSource.afterPropertiesSet(); &#125; /** * 初始化其他数据源 * * @param analysisDataSource */ @Override public void initOthersDataSource(AnalysisDataSource analysisDataSource) &#123; if (analysisDataSource == null || StringUtils.isBlank(analysisDataSource.getId())) &#123; return; &#125; DruidDataSource druidDataSource = new DruidDataSource(); druidDataSource.setUsername(analysisDataSource.getUsername()); druidDataSource.setPassword(analysisDataSource.getPassword()); //在此处可以查询出所有的数据源（例如，配置文件，数据库）然后添加 druidDataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); druidDataSource.setUrl(\"jdbc:mysql://\" + analysisDataSource.getUrl() + \"?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true\"); //添加数据源到map addDataSource(analysisDataSource.getId(), druidDataSource); &#125; public synchronized Connection getPoolConnection() &#123; Connection connection = null; try &#123; connection = Config.getPool().getConnection(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return connection; &#125; @Override protected Object determineCurrentLookupKey() &#123; //获取当前线程的数据源，如果不存在使用master数据源 String datasource = getDataSource(); if (com.mysql.jdbc.StringUtils.isNullOrEmpty(datasource)) &#123; datasource = \"master\"; &#125; logger.info(\"mysql-datasource=\" + datasource); return datasource; &#125;&#125; 借鉴文章如下SpringBoot重点详解–整合hive-jdbcSpringBoot整合hive-jdbc遇到的坑","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://zhuangyea.github.io/tags/java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://zhuangyea.github.io/tags/SpringBoot/"}]},{"title":"Logstash实现mysql同步数据到elasticsearch","slug":"elk/Logstash实现mysql同步数据到elasticsearch","date":"2019-03-28T12:00:00.000Z","updated":"2019-08-22T07:56:07.627Z","comments":true,"path":"2019/03/28/elk/Logstash实现mysql同步数据到elasticsearch/","link":"","permalink":"http://zhuangyea.github.io/2019/03/28/elk/Logstash实现mysql同步数据到elasticsearch/","excerpt":"","text":"Logstash安装： 下载安装包：wget https://artifacts.elastic.co/downloads/logstash/logstash-6.6.2.tar.gz 下载mysql的连接库jar包(版本库)：wget http://central.maven.org/maven2/mysql/mysql-connector-java/6.0.6/mysql-connector-java-6.0.6.jar 解压安装包：tar -xvf logstash-6.6.2.tar.gz 安装jdbc、elasticsearch插件:1234logstash插件安装命令cd logstash-6.6.2/bin./logstash-plugin install logstash-input-jdbc./logstash-plugin install logstash-output-elasticsearch 创建配置文件在config目录下，创建配置文件（logstash-mysql-es.conf）： input { # stdin { } jdbc { jdbc_connection_string =&gt; &quot;jdbc:mysql://localhost:30012/data_acquisition?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&quot; jdbc_user =&gt; &quot;root&quot; jdbc_password =&gt; &quot;123456&quot; jdbc_driver_library =&gt; &quot;/path/mysql-connector-java-6.0.6.jar&quot; #全路径 jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;50000&quot; statement =&gt; &quot;select * from result_comment where create_time &gt;= &apos;2019-03-20&apos;&quot; #schedule =&gt; &quot;* * * * *&quot; } } output { # 这里输出调试，正式运行时可以注释掉 stdout { codec =&gt; json_lines } elasticsearch { hosts =&gt; &quot;127.0.0.1:9200&quot; index =&gt; &quot;wl_travel_analyze&quot; document_type =&gt; &quot;travel&quot; document_id =&gt; &quot;%{id}&quot; #ssl =&gt; true #ssl_certificate_verification =&gt; true #truststore =&gt; &quot;/opt/elk/search-guard-tlstool/search-guard-certificates/truststore.jks&quot; #truststore_password =&gt; &quot;286a7b7a8970af4e8467&quot; user =&gt; &quot;admin&quot; password =&gt; &quot;admin&quot; } }注意添加ElasticSearch用户名和密码 启动改脚本nohup ./bin/logstash -f config/logstash-mysql-es.conf &gt; logs/logstash.out &amp; 查看日志tail -f logs/logstash.out 借鉴文章如下:Elasticsearch - Logstash实现mysql同步数据到elasticsearch","categories":[],"tags":[{"name":"elk","slug":"elk","permalink":"http://zhuangyea.github.io/tags/elk/"}]},{"title":"ELK之ElasticSearch 6.X安全认证Search Guard(demo01)","slug":"elk/基于SearchGuard对ElasticSearch进行权限访问控制","date":"2019-03-27T12:00:00.000Z","updated":"2019-08-22T07:50:32.083Z","comments":true,"path":"2019/03/27/elk/基于SearchGuard对ElasticSearch进行权限访问控制/","link":"","permalink":"http://zhuangyea.github.io/2019/03/27/elk/基于SearchGuard对ElasticSearch进行权限访问控制/","excerpt":"","text":"ElasticSearch单节点安装Search Guard插件 12345版本介绍： ElasticSearch：6.6.2 Logstash：6.6.2 Kibana：6.6.2 Search Guard：6.6.2-24.2 Search Guard（安全认证）插件安装 切换到ElasticSearch安装目录，通过使用elasticsearch plugin命令安装Search Guard插件 1./bin/elasticsearch-plugin install -b com.floragunn:search-guard-6:&lt;version&gt; 参数参考: https://github.com/floragunncom/search-guard/wiki 1例：./bin/elasticsearch-plugin install -b com.floragunn:search-guard-6:6.6.2-24.2 基于在线方式生成TLS证（官方提供多中方式生成）&nbsp;&nbsp;&nbsp;在线生成地址：https://search-guard.com/tls-certificate-generator/服务器hosts配置 配置证书证书文件会发送到邮箱中，目录结构如下。详细描述参考证书目录下README.txt123456789101112131415161718192021222324search-guard-certificates-&lt;UUID&gt;.tar.gz│└─── client-certificates│ Contains two client certificates named &apos;admin&apos; and &apos;demouser&apos;│ The &apos;admin&apos; certificate can be used with sgadmin and the REST API.│ The CN of this certificate is &apos;sgadmin&apos;. The demouser certificate can be used│ for HTTPS client authentication. The CN of this certificate is &apos;demouser&apos;└─── node-certificates│ Contains the certificates in jks, p12 and pem format to be used│ on your Elasticsearch nodes. You will find certificates for all│ hostnames you specified when submitting the form.└─── root-ca│ Contains the root CA certificate and private key in PEM format.└─── config│ Same as above, but for the signing CA└─── truststore.jks│ The truststore containing the certificate chain│ of the root and signing CA, and the root certificate and private key in PEM format.│ Can be used on all nodes.└─── root-ca.pem│ The root CA in PEM format.│ Can be used on all nodes.└─── chain-ca.pem│ The certificate chain containg the root and signing CA in PEM format. 参考README.txt 复制证书及修改ES_HOME/config/elasticsearch.yml配置，配置如下： 1234567891011121314151617181920212223242526272829/** 复制证书 node-certificates：证书目录 ES_HOME：elasticsearch安装目录 SG_HOME：ES_HOME/plugins/search-guard-6(插件安装目录)**/cp node-certificates/CN=[hostname].crtfull.pem ES_HOME/config/cp node-certificates/CN=[hostname].key.pem ES_HOME/config/cp node-certificates/chain-ca.pem ES_HOME/config/cp node-certificates/truststore.jks SG_HOME/tools/cp node-certificates/client-certificates/CN=sgadmin-keystore.jks SG_HOME/tools/修改es配置文件xpack.security.enabled: falsesearchguard.ssl.transport.pemcert_filepath: CN=node-01.crtfull.pemsearchguard.ssl.transport.pemkey_filepath: CN=node-01.key.pemsearchguard.ssl.transport.pemkey_password: 密码查看看README.txtsearchguard.ssl.transport.pemtrustedcas_filepath: chain-ca.pemsearchguard.ssl.transport.enforce_hostname_verification: falsesearchguard.ssl.http.enabled: falsesearchguard.ssl.http.pemcert_filepath: CN=node-01.crtfull.pemsearchguard.ssl.http.pemkey_filepath: CN=node-01.key.pemsearchguard.ssl.http.pemkey_password: 密码查看看README.txtsearchguard.ssl.http.pemtrustedcas_filepath: chain-ca.pemsearchguard.authcz.admin_dn: - CN=sgadmin# - CN=demouser 至此配置告一段落，切换用户启动es,执行以下命令,注意密码查看README.txt 123cd ES_HOME/plugins/search-guard-&lt;version&gt;/toolschmod 755 ./sgadmin.sh./sgadmin.sh -ts truststore.jks -tspass 286a7b7a8970af4e8467 -ks CN=sgadmin-keystore.jks -kspass 449e1fcd3cba8bb7d491 -nhnv -icl -cd ../sgconfig/ 命令输出如下 见证奇迹时刻！！！打开浏览器输入http://IP:9200/_searchguard/authinfo，成功弹出登录提示框！输入admin：admin登录成功 权限配置&nbsp;&nbsp;&nbsp;&nbsp;创建一个用户:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;–用户名：colin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;–密码：colin，&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;–权限：kibana服务权限、只有索引【colin】crud权限，没有logstash权限）1234567891011121314151617181920212223242526272829303132内部数据库目录结构（ES_HOME/plugins/search-guard-&lt;version&gt;/sgconfig/） --sg_internal_users.yml 用户信息 --sg_roles.yml 权限设置 --sg_roles_mapping.yml 映射权限和用户关系#创建用户vim sg_internal_users.yml #添加用户信息#password is: colincolin: readonly: true hash: $2y$12$8YYO/iYi1k31G5avwHonfOGfv5F/NTIMzPxtziVBg8FIf3q979iiO roles: - sg_role_colin - kibanauser#添加权限vim sg_roles.yml #添加权限sg_role_colin: cluster: - UNLIMITED indices: &apos;colin&apos;: &apos;*&apos;: - INDICES_ALL# _dls_: &apos;&lt;dls query&gt;&apos;# _fls_:# - &apos;&lt;field&gt;&apos;# - &apos;&lt;field&gt;&apos;#使配置立即生效cd ES_HOME/plugins/search-guard-&lt;version&gt;/tools./sgadmin.sh -ts truststore.jks -tspass 286a7b7a8970af4e8467 -ks CN=sgadmin-keystore.jks -kspass 449e1fcd3cba8bb7d491 -nhnv -icl -cd ../sgconfig/ 权限配置完成通过kibana查看效果，如下 查询colin索引，结果正常 查询wl_travel索引，提示无权操作 下一篇介绍SpringBoot2.X连接ElasticSearch 结语：有很多地方还没弄明白，稀里糊涂配置完！反正是能用了，对不对就不知道。","categories":[],"tags":[{"name":"elk","slug":"elk","permalink":"http://zhuangyea.github.io/tags/elk/"}]},{"title":"SpringBoot2.X连接ElasticSearch集成Search Guard","slug":"elk/SpringBoot2.X连接ElasticSearch集成SearchGuard","date":"2019-03-27T12:00:00.000Z","updated":"2019-08-22T07:43:12.688Z","comments":true,"path":"2019/03/27/elk/SpringBoot2.X连接ElasticSearch集成SearchGuard/","link":"","permalink":"http://zhuangyea.github.io/2019/03/27/elk/SpringBoot2.X连接ElasticSearch集成SearchGuard/","excerpt":"","text":"前言先说需求吧，我的需求：不同项目分配不同用户，用户数据独立；但是我在网上找了很多资料都是基于证书实现连接的，疑问如下&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.如何生成多个证书？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.证书如何分配权限？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.如何使多个证书同时生效？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.能否基于用户名密码方式连接带着几点疑问开始了编程之旅!!! 废话不多数直接上代码，官方文档123456789版本介绍： JDK：1.8 SpringBoot：2.0.1 ElasticSearch：6.6.2 Search Guard：6.6.2-24.2需要准备证书（上篇文章中在线生成证书中有这些文件） demouser-keystore.jks sgadmin-keystore.jks truststore.jks 证书来源参考：https://www.jianshu.com/p/de341fdb2789 配置目录结构及配置文件 pom.xml文件配置1234567891011121314151617181920212223242526272829303132333435&lt;properties&gt; &lt;spring.boot.version&gt;2.0.1.RELEASE&lt;/spring.boot.version&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;elasticsearch.version&gt;6.6.2&lt;/elasticsearch.version&gt; &lt;/properties&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加 transport-netty4-client maven 依赖之后可以成功获取到连接 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.plugin&lt;/groupId&gt; &lt;artifactId&gt;transport-netty4-client&lt;/artifactId&gt; &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.floragunn&lt;/groupId&gt; &lt;artifactId&gt;search-guard-6&lt;/artifactId&gt; &lt;version&gt;6.6.2-24.2-api&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.10&lt;/version&gt; &lt;/dependency&gt; ElasticSearchClient.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package com.isoftstone.ismart.elastic.config;import com.floragunn.searchguard.ssl.SearchGuardSSLPlugin;import com.floragunn.searchguard.ssl.util.SSLConfigConstants;import org.apache.commons.codec.binary.Base64;import org.apache.commons.lang3.StringUtils;import org.elasticsearch.action.admin.cluster.node.info.NodesInfoRequest;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.settings.Settings;import org.elasticsearch.common.transport.TransportAddress;import org.elasticsearch.transport.client.PreBuiltTransportClient;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.net.InetAddress;import java.net.URL;import java.net.URLDecoder;/** * @author Colin.Ye * @version 1.0 * @ClassName ElasticSearchClient * @date 2019/3/25 **/@Configurationpublic class ElasticSearchClient &#123; @Value(\"$&#123;spring.data.elasticsearch.cluster-nodes&#125;\") private String nodes; @Value(\"$&#123;spring.data.elasticsearch.cluster-name&#125;\") private String custerName; @Value(\"$&#123;spring.data.elasticsearch.ssl-keystore-password&#125;\") private String sslKeystorePassword; @Value(\"$&#123;spring.data.elasticsearch.ssl-truststore-password&#125;\") private String sslTruststorePassword; //注入的ElasticSearch实例 @Bean(name = \"esClient\") public TransportClient getclient() throws Exception &#123; ClassLoader classLoader = ElasticSearchClient.class.getClassLoader(); URL resource = classLoader.getResource(\"ca/demouser-keystore.jks\");// URL resource = classLoader.getResource(\"ca/sgadmin-keystore.jks\"); URL truresource = classLoader.getResource(\"ca/truststore.jks\"); String keypath = URLDecoder.decode(resource.getPath(), \"UTF-8\"); String trupath = URLDecoder.decode(truresource.getPath(), \"UTF-8\"); //windows中路径会多个/ 如/E windows下需要打开注释 try &#123; String osName = System.getProperty(\"os.name\"); if (StringUtils.contains(osName, \"Windows\")) &#123; if (keypath.startsWith(\"/\")) &#123; keypath = keypath.substring(1, keypath.length()); &#125; if (trupath.startsWith(\"/\")) &#123; trupath = trupath.substring(1, trupath.length()); &#125; &#125; &#125; catch (Exception e) &#123; System.out.println(e); &#125; Settings settings = Settings.builder() .put(\"cluster.name\", custerName) .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_ENABLED, true) .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_KEYSTORE_FILEPATH, keypath) .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_TRUSTSTORE_FILEPATH, trupath) .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_KEYSTORE_PASSWORD, sslKeystorePassword) .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_TRUSTSTORE_PASSWORD, sslTruststorePassword) .put(SSLConfigConstants.SEARCHGUARD_SSL_HTTP_KEYSTORE_PASSWORD, sslKeystorePassword) .put(SSLConfigConstants.SEARCHGUARD_SSL_HTTP_TRUSTSTORE_PASSWORD, sslTruststorePassword) .put(\"client.transport.ignore_cluster_name\", true) .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_ENFORCE_HOSTNAME_VERIFICATION, false) .build(); TransportClient client = new PreBuiltTransportClient(settings, SearchGuardSSLPlugin.class);// TransportClient client = new PreBuiltTransportClient(settings);// System.out.println(\"Basic \" + new String(Base64.encodeBase64(\"admin:admin\".getBytes())));// client.threadPool().getThreadContext().putHeader(\"Authorization\",// \"Basic \" + new String(Base64.encodeBase64(\"admin:admin\".getBytes()))); try &#123; String[] nodeArray = nodes.split(\",\"); for (String node : nodeArray) &#123; String[] nodeArr = node.split(\":\"); client.addTransportAddress(new TransportAddress(InetAddress.getByName(nodeArr[0]), Integer.parseInt(nodeArr[1]))); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;// client.admin().cluster().nodesInfo(new NodesInfoRequest()).actionGet(); return client; &#125;&#125; LowCreateIndexDemo.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249package com.isoftstone.ismart.elastic.controller;import com.alibaba.fastjson.JSONArray;import com.alibaba.fastjson.JSONObject;import com.isoftstone.ismart.elastic.model.result.Result;import com.isoftstone.ismart.elastic.model.result.ResultCode;import org.apache.commons.codec.binary.Base64;import org.apache.commons.lang3.StringUtils;import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;import org.elasticsearch.action.index.IndexResponse;import org.elasticsearch.action.search.SearchResponse;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.settings.Settings;import org.elasticsearch.common.xcontent.XContentType;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.SearchHit;import org.elasticsearch.search.SearchHits;import org.elasticsearch.search.fetch.subphase.highlight.HighlightBuilder;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import javax.servlet.http.HttpServletRequest;import java.util.Map;import java.util.UUID;/** * @author Colin.Ye * @version 1.0 * @ClassName LowCreateIndexDemo * @date 2019/3/13 **/@RestController@RequestMapping(\"/lowClient/v1/\")@CrossOriginpublic class LowCreateIndexDemo &#123; @Autowired public TransportClient client; /** * 创建索引 * * @param index * @param json * @return */ @RequestMapping(value = \"createIndex/&#123;index&#125;/&#123;type&#125;\", method = &#123;RequestMethod.POST, RequestMethod.PUT&#125;) public Result createIndex(HttpServletRequest httpRequest, @PathVariable String index, @PathVariable String type, @RequestBody String json) &#123; // 1、创建 创建索引request try &#123; if (StringUtils.isBlank(index) || StringUtils.isBlank(type)) &#123; return Result.failure(ResultCode.PARAM_NOT_INDEX); &#125; if (StringUtils.isBlank(json)) &#123; return Result.failure(ResultCode.PARAM_NOT_SETTING); &#125; CreateIndexRequest request = new CreateIndexRequest(index); JSONObject reqJson; try &#123; reqJson = JSONObject.parseObject(json); &#125; catch (Exception e) &#123; return Result.failure(ResultCode.PARAM_JSON_ERROR); &#125; /** * 2、设置索引的settings * index.number_of_shards：分片数 * index.number_of_replicas：副本数 * analysis.analyzer.default.tokenizer：默认分词器 * ik_max_word：会将文本做最细粒度的拆分 * ik_smart：会做最粗粒度的拆分 * standard：默认分词器 */ JSONObject settingJson = reqJson.getJSONObject(\"settings\"); Integer shards = 3; Integer replicas = 2; String analysis = \"standard\"; if (settingJson != null) &#123; shards = settingJson.getInteger(\"shards\"); replicas = settingJson.getInteger(\"replicas\"); analysis = settingJson.getString(\"analysis\") == null ? \"standard\" : settingJson.getString(\"analysis\"); &#125; request.settings(Settings.builder().put(\"index.number_of_shards\", shards) .put(\"index.number_of_replicas\", replicas) .put(\"analysis.analyzer.default.tokenizer\", analysis) ); JSONObject array = reqJson.getJSONObject(\"mapping\"); if (array != null &amp;&amp; array.size() &gt; 0) &#123; JSONObject jsonObject = new JSONObject(); jsonObject.put(type, new JSONObject() &#123;&#123; put(\"properties\", new JSONObject() &#123;&#123; for (Entry&lt;String, Object&gt; obj : array.entrySet()) &#123; put(obj.getKey(), new JSONObject() &#123;&#123; put(\"type\", obj.getValue().toString()); &#125;&#125;); &#125; &#125;&#125;); &#125;&#125;); System.out.println(jsonObject.toJSONString()); // 3、设置索引的mappings request.mapping(type, jsonObject.toJSONString(), XContentType.JSON); &#125; // 4、 设置索引的别名// request.alias(new Alias(\"mmm\")); // 5、 发送请求 这里和RESTful风格不同 boolean b = setAuthHeader(httpRequest); if (!b) &#123; return Result.failure(ResultCode.PERMISSION_NO_ACCESS); &#125; CreateIndexResponse createIndexResponse = client.admin().indices().create(request).get(); // 6、处理响应 JSONObject jsonObject = new JSONObject(); jsonObject.put(\"acknowledged\", createIndexResponse.isAcknowledged()); jsonObject.put(\"shardsAcknowledged\", createIndexResponse.isAcknowledged()); return Result.success(jsonObject); &#125; catch (Exception e) &#123; e.printStackTrace(); return Result.failure(ResultCode.SPECIFIED_QUESTIONED_USER_NOT_EXIST, e.getMessage()); &#125; &#125; /** * 添加文档 * * @param index * @return */ @RequestMapping(value = \"/save/&#123;index&#125;/&#123;type&#125;\", method = RequestMethod.POST) public Result save(HttpServletRequest httpRequest, @PathVariable String index, @PathVariable String type, @RequestBody String json) &#123; if (StringUtils.isBlank(index) || StringUtils.isBlank(type)) &#123; return Result.failure(ResultCode.PARAM_NOT_INDEX); &#125; if (StringUtils.isBlank(json)) &#123; return Result.failure(ResultCode.PARAM_NOT_SETTING); &#125; JSONObject jsonObject = JSONObject.parseObject(json); if (jsonObject == null) &#123; return Result.failure(ResultCode.PARAM_IS_BLANK); &#125; String id = jsonObject.getString(\"id\"); if (StringUtils.isBlank(id)) &#123; id = UUID.randomUUID().toString().replaceAll(\"-\", \"\"); &#125; boolean b = setAuthHeader(httpRequest); if (!b) &#123; return Result.failure(ResultCode.PERMISSION_NO_ACCESS); &#125; IndexResponse response = client.prepareIndex(index, type, id).setSource(jsonObject.getInnerMap()).execute().actionGet(); return Result.success(response.toString()); &#125; /** * 查询数据 * * @param index * @param type * @param json * @return */ @RequestMapping(value = \"/search/&#123;index&#125;/&#123;type&#125;/&#123;page&#125;/&#123;pageSize&#125;\", method = RequestMethod.POST) public Result search(HttpServletRequest httpRequest, @PathVariable String index, @PathVariable String type, @PathVariable Integer page, @PathVariable Integer pageSize, @RequestBody String json) &#123; try &#123; // 构造查询对象的工厂类 QueryBuilders,matchQuery全文查询,Operator.AND指定分词项之间采用AND方式连接,默认是OR BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); // 3.设置boolQueryBuilder条件 // 子boolQueryBuilder条件条件，用来表示查询条件or的关系 JSONObject jsonObject = JSONObject.parseObject(json); for (Map.Entry&lt;String, Object&gt; entry : jsonObject.entrySet()) &#123; boolQueryBuilder.must(QueryBuilders.matchQuery(entry.getKey(), entry.getValue().toString())); &#125; BoolQueryBuilder childBoolQueryBuilder = new BoolQueryBuilder() .should(QueryBuilders.matchPhraseQuery(\"comment_content\", \"1\")) .should(QueryBuilders.matchPhraseQuery(\"comment_content\", \"2\")); // 4.添加查询条件到boolQueryBuilder中// boolQueryBuilder// .must(childBoolQueryBuilder);// .must(QueryBuilders.matchQuery()); //构造HighlightBuilder对象,设置需要高亮的字段并自定义高亮标签 HighlightBuilder highlighter = new HighlightBuilder() .field(\"comment_content\") .preTags(\"&lt;span stype=\\\"color:red\\\"&gt;\") .postTags(\"&lt;/span&gt;\"); boolean b = setAuthHeader(httpRequest); if (!b) &#123; return Result.failure(ResultCode.PERMISSION_NO_ACCESS); &#125; SearchResponse response = client.prepareSearch(index) .setTypes(type) .setQuery(boolQueryBuilder) .highlighter(highlighter) .setSize(pageSize) .setFrom(page)// .addSort(\"create_time\", SortOrder.DESC) .get(); //通过上面获得的SearchResponse对象,取得返回结果 SearchHits hits = response.getHits(); //搜索到的结果数// System.out.println(\"共搜索到:\" + hits.getTotalHits()); JSONArray array = new JSONArray(); //遍历SearchHits数组 for (SearchHit hit : hits) &#123; array.add(JSONObject.parse(hit.getSourceAsString()));// System.out.println(\"Source:\" + hit.getSourceAsString());//返回String类型的文档内容// System.out.println(\"Source As Map:\" + hit.getSource());//返回Map格式的文档内容// System.out.println(\"Index:\" + hit.getIndex());//返回文档所在的索引// System.out.println(\"Type:\" + hit.getType());//返回文档所在的类型// System.out.println(\"ID:\" + hit.getId());//返回文档的id// System.out.println(\"Source:\" + hit.getSource().get(\"price\"));//从返回的map中通过key取到value// System.out.println(\"Score:\" + hit.getScore());//返回文档的评分 //getHighlightFields()会返回文档中所有高亮字段的内容，再通过get()方法获取某一个字段的高亮片段,最后调用getFragments()方法，返回Text类型的数组// Text[] texts = hit.getHighlightFields().get(\"title\").getFragments();// if(texts != null) &#123;// //遍历高亮结果数组,取出高亮内容// for (Text text : texts) &#123;// System.out.println(text.string());// &#125;// &#125; &#125; return Result.success(array); &#125;catch (Exception e)&#123; return Result.failure(ResultCode.SPECIFIED_QUESTIONED_USER_NOT_EXIST, e.getMessage()); &#125; &#125; // 获取请求消息头中的用户信息，格式【用户名:密码】 private boolean setAuthHeader(HttpServletRequest httpRequest) &#123; String authorization = httpRequest.getHeader(\"Authorization\"); if (StringUtils.isNotBlank(authorization)) &#123; client.threadPool().getThreadContext().putHeader(\"Authorization\", \"Basic \" + new String(Base64.encodeBase64(authorization.getBytes()))); return true; &#125; return false; &#125;&#125; 效果图 使用colin用户访问colin数据 使用colin用户访问其他索引数据 使用admin用户访问数据 结语 ：经过一天时间总算是实现了，但是为什么这样就行，我也不知道！！！ 使用sgadmin-keystore.jks，不需要在请求时添加消息头 使用demouser-keystore.jks，需要每次请求时添加用户信息消息头 借鉴文章如下:SearchGuard 实践elasticsearch系列七：ES Java客户端-Elasticsearch Java clientElasticsearch使用searchguard后Java连接及安全验证","categories":[],"tags":[{"name":"elk","slug":"elk","permalink":"http://zhuangyea.github.io/tags/elk/"}]},{"title":"ElasticSearch插件SearchGuard/IK安装","slug":"elk/ElasticSearch插件SearchGuard及IK安装","date":"2019-03-25T13:20:00.000Z","updated":"2019-03-26T01:44:43.434Z","comments":true,"path":"2019/03/25/elk/ElasticSearch插件SearchGuard及IK安装/","link":"","permalink":"http://zhuangyea.github.io/2019/03/25/elk/ElasticSearch插件SearchGuard及IK安装/","excerpt":"","text":"1.Search Guard（安全认证） 切换到elasticsearch目录，通过使用elasticsearch plugin命令安装Search Guard插件 1./bin/elasticsearch-plugin install -b com.floragunn:search-guard-6:&lt;version&gt; 参数参考: https://github.com/floragunncom/search-guard/wiki 1例：./bin/elasticsearch-plugin install -b com.floragunn:search-guard-6:6.6.2-24.2 IK分词器 切换到elasticsearch目录，通过使用elasticsearch plugin命令安装IK插件 1./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v&lt;version&gt;/elasticsearch-analysis-ik-&lt;version&gt;.zip 参数参考: https://github.com/medcl/elasticsearch-analysis-ik/releases 1例：./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.6.2/elasticsearch-analysis-ik-6.6.2.zip","categories":[],"tags":[{"name":"elk","slug":"elk","permalink":"http://zhuangyea.github.io/tags/elk/"}]},{"title":"SpringBoot连接MongoDB(单节点)","slug":"java/SpringBoot连接MongoDB(单节点)","date":"2019-03-25T13:20:00.000Z","updated":"2019-11-11T09:52:33.451Z","comments":true,"path":"2019/03/25/java/SpringBoot连接MongoDB(单节点)/","link":"","permalink":"http://zhuangyea.github.io/2019/03/25/java/SpringBoot连接MongoDB(单节点)/","excerpt":"","text":"pom.xml（SpringBoot版本1.5.9） 12345&lt;!-- 集成mongodb --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 1234567#mongodb配置spring: data: mongodb: host: ip port: port database: ismart 实体类参考 1234567891011121314151617181920212223242526272829303132333435package com.colin.fdfs.model;import org.springframework.data.annotation.Id;import org.springframework.data.mongodb.core.mapping.Document;import java.text.SimpleDateFormat;import java.util.Date;/** * Created by colin on 2018/7/4. */@Document(collection = \"ismartFastdfs\")public class Fastdfs &#123; public static final String COLLECTION_KEY = \"ismartFastdfs\"; public static final String CREATE_TIME = \"createTime\"; public static final String SYSTEM_ID = \"systemId\"; @Id private String id; private String fileName; private long fileSize; private Date createTime; private String ipHost; private String filePath; private String uploadType; private String systemId; private String httpUrl; private String createTimeStr; private String stime; private String etime; // TODO 此处省略get/set方法&#125; 分页查询 12345678910111213141516171819202122232425262728@Autowiredprivate MongoTemplate mongoTemplate;public void demo01() &#123; Criteria c = new Criteria(); if (params != null &amp;&amp; params.size() &gt; 0) &#123; for (Map.Entry&lt;String, Object&gt; entry : params.entrySet()) &#123; c.and(entry.getKey()).is(entry.getValue()); &#125; &#125; /** * (num-1) * pageSize * 1 10 0 10 * 2 10 10 10 * 3 10 20 10 */ if (pageNum == null) &#123; pageNum = 1; &#125; if (pageSize == null) &#123; pageSize = 10; &#125; List&lt;ReadingHistory&gt; data = mongoTemplate.find(Query.query(c) .with(new Sort(Sort.Direction.DESC, \"mdbCreatedAt\")) // 排序 .skip((pageNum - 1) * pageSize) //当前页 .limit(pageSize), // 每页条数 ReadingHistory.class, \"collectionHistory\");&#125; 聚合查询-根据时间分组、排序 &nbsp;&nbsp;&nbsp;&nbsp;数据结构如下图 123456789101112131415161718192021222324252627 public void count() &#123; // 根据部门和时间统计上传图片数量，时间倒序 Aggregation agg = Aggregation.newAggregation(// Aggregation.match(Criteria.where(\"moduleId\").is(\"ismart\")), Aggregation.project(\"moduleId\") .and(DateOperators.DateToString.dateOf(\"createTime\") .toString(\"%Y-%m-%d\")).as(\"date\"), Aggregation.group(\"date\",\"moduleId\").count().as(\"total\"), Aggregation.sort(Sort.Direction.DESC, \"date\",\"moduleId\") ); // 输出数据 AggregationResults&lt;JSONObject&gt; a = mongoTemplate.aggregate(agg, \"fastdfs\", JSONObject.class); System.out.println(a); List&lt;JSONObject&gt; list = a.getMappedResults(); for (JSONObject count : list) &#123; System.out.println(count.toString()); &#125; &#125; 输出结果如下： &#123;\"date\":\"2019-04-11\",\"total\":2,\"moduleId\":\"ismart\"&#125; &#123;\"date\":\"2019-04-11\",\"total\":750,\"moduleId\":\"industrial\"&#125; &#123;\"date\":\"2019-04-10\",\"total\":1239,\"moduleId\":\"ismart\"&#125; &#123;\"date\":\"2019-04-10\",\"total\":973,\"moduleId\":\"industrial\"&#125; &#123;\"date\":\"2019-04-08\",\"total\":1367,\"moduleId\":\"ismart\"&#125; &#123;\"date\":\"2019-04-08\",\"total\":2080,\"moduleId\":\"industrial\"&#125; ... 需注意SpringBoot版本问题。使用1.5.9.RELEASE版本聚合查询一直报错（如上图），解决方案：升级SpringBoot版本至1.5.10.RELEASE。 聚合语法参考： SQL 操作/函数 mongodb聚合操作 where $match group by $group having $match select $project order by $sort limit $limit sum() $sum count() $sum join $lookup（v3.2 新增） 借鉴文章如下:mongodb高级聚合查询","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://zhuangyea.github.io/tags/java/"}]},{"title":"springboot启动类（Application.java）中配置线程池大小","slug":"java/thread","date":"2019-03-25T13:20:00.000Z","updated":"2019-08-22T07:32:09.292Z","comments":true,"path":"2019/03/25/java/thread/","link":"","permalink":"http://zhuangyea.github.io/2019/03/25/java/thread/","excerpt":"","text":"123456789@Bean(name = \"crawlExecutorPool\") public ExecutorService crawlExecutorPool() &#123; // 获取Java虚拟机的可用的处理器数，最佳线程个数，处理器数*2。根据实际情况调整 int curSystemThreads = Runtime.getRuntime().availableProcessors() * 2; System.out.println(\"------------系统可用线程池个数：\" + curSystemThreads); // 创建线程池 ExecutorService pool = Executors.newFixedThreadPool(curSystemThreads); return pool; &#125; 使用类中注入线程池并使用 12345678910111213141516@Autowired@Qualifier(value = \"crawlExecutorPool\")private ExecutorService pool;public void crawlRedisQueue() &#123; for (int i = 0; i &lt; 2000000; i++) &#123; pool.execute(() -&gt; &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"======定时任务执行完成======\"); &#125;); &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://zhuangyea.github.io/tags/java/"}]},{"title":"markdown基本语法","slug":"markdown基本语法","date":"2019-01-07T12:36:13.000Z","updated":"2019-08-23T09:34:23.983Z","comments":true,"path":"2019/01/07/markdown基本语法/","link":"","permalink":"http://zhuangyea.github.io/2019/01/07/markdown基本语法/","excerpt":"","text":"我是标题# 我是标题 我是小一号标题`## 我是小一号标题`` 我是小小一号标题### 我是小小一号标题 我是小小小一号标题#### 我是小小小一号标题 我是小小小小一号标题##### 我是小小小小一号标题 我是最小标题###### 我是最小标题 加粗**字体加粗** 字体倾斜*字体倾斜* 斜体加粗的文字***斜体加粗的文字*** 删除线文字~~删除线文字~~ 我是红色字体&lt;font color=&quot;red&quot; size=&quot;4&quot;&gt;我是号红色字体&lt;/font&gt; 我是引用 1&gt; 我是引用 我是连接 1- [我是连接](https://zhuangyea.github.io/) 123![image](/img/source/20180811192750229.png &quot;我是图片描述&quot;)另一种方式：&lt;img src=&quot;/img/source/20180811192750229.png&quot; title=&quot;我是图片描述&quot; width=&quot;200px&quot;/&gt; 华丽丽的分割线12---*** 表格 左侧表格1 居中表格2 右侧表格3 你好啊 咧好啊 雷好啊 12345&lt;font color=&quot;red&quot;&gt;*&lt;/font&gt;表格上方空一行左侧表格1|居中表格2|右侧表格3-|:-:|-:你好啊|咧好&lt;br/&gt;啊|雷好啊 自定义表格 表格1 表格2 表格3 a1 a2 b1 b2 b3 c2 c3 需要注意的一点是，在markdown中使用html代码来实现表格的效果，需要在表格的外面套上（转义），防止markdown直接将代码中的行进行转义成回车，不然会出现表格前空了一大块空白。12345678910111213141516171819202122&lt;escape&gt;&lt;table&gt; &lt;tr&gt; &lt;th&gt;表格1&lt;/th&gt; &lt;th&gt;表格2&lt;/th&gt; &lt;th&gt;表格3&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;a1&lt;/td&gt; &lt;td colspan=&quot;2&quot;&gt;a2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan=&quot;2&quot;&gt;b1&lt;/td&gt; &lt;td&gt;b2&lt;/td&gt; &lt;td&gt;b3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;c2&lt;/td&gt; &lt;td&gt;c3&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/escape&gt; 无序段落 段落2 段落3 123- 无序段落 - 段落2 - 段落3 有序段落 段落2 段落3 123注意.后面加空格1. 段落22. 段落3 借鉴文章如下：Markdown基本语法解决在Markdown中的表格单元格合并的问题","categories":[{"name":"前端","slug":"前端","permalink":"http://zhuangyea.github.io/categories/前端/"}],"tags":[{"name":"html","slug":"html","permalink":"http://zhuangyea.github.io/tags/html/"}]},{"title":"markdown基本布局","slug":"markdown基本布局","date":"2019-01-07T12:36:13.000Z","updated":"2019-08-23T09:34:23.990Z","comments":true,"path":"2019/01/07/markdown基本布局/","link":"","permalink":"http://zhuangyea.github.io/2019/01/07/markdown基本布局/","excerpt":"","text":"目录 一、前言 二、Apache poi、jxl 的缺陷 三、阿里出品的 EasyExcel，安利一波 四、EasyExcel 解决了什么 五、快速上手 六、特殊场景支持 七、Web 下载示例代码 八、需要注意的点 九、总结 一、前言 关于导出 Excel 文件，可以说是大多数服务中都需要集成的功能。那么，要如何优雅快速地（偷懒地）去实现这个功能呢？ 你可能第一想法是：这还不简单？用 Apache 开源框架 poi, 或者 jxl 都可以实现啊。面向百度编程，把代码模板 copy 下来，根据自己的业务再改改，能有多难？ 二、目录1 ①：阿斯蒂芬 ②：阿斯蒂芬 asdfasdfasdfasdfs import com.com.com 区别 PC端 移动端 1 2s 3 4 5 6 项目1 项目2 项目3 a1 a2 b1 b2 b3 c2 c3 布局参考","categories":[{"name":"前端","slug":"前端","permalink":"http://zhuangyea.github.io/categories/前端/"}],"tags":[{"name":"html","slug":"html","permalink":"http://zhuangyea.github.io/tags/html/"}]},{"title":"产品设计2","slug":"产品设计2","date":"2019-01-07T12:36:13.000Z","updated":"2019-08-22T07:20:34.133Z","comments":true,"path":"2019/01/07/产品设计2/","link":"","permalink":"http://zhuangyea.github.io/2019/01/07/产品设计2/","excerpt":"","text":"4 交互设计4.1 交互概论回顾产品结构：基于前期的需求分析及市场竞品分析等为依据，将各个需求点以及某种逻辑系统化的组织起来所形成的立体结构。基于该结构，可以顺利的引导用户行为或将各类信息进行顺畅的流转 操作系统从最初的DOC系统&gt;win98&gt;winXP&gt;win7&gt;win8&gt;win10,从最初专业到普及就是交互设计的不断改进。 UI 用户界面 UE 用户体验 IXD 交互设计 什么是交互： 两个或多个互动的个体之间交流的内容和结构，使之互相配合，共同达成某种目的。交互设计就是让用户在使用产品或服务的过程保证可用性，提高易用性。 交互设计是一种使得产品易用，有效的把人使用产品的过程变得愉悦的技术。它致力于把握目标用户和他们的期望，分析“人”本身的心里和行为特点，设计或改善用户在同产品交互时彼此的有效行为，和各种有效的交互方式，并对他们进行增强和扩充。 4.2 交互设计中的基本原则 用户心理现在有一把锁，从不同角度来看 用户： 眼中：钥匙眼+把手 心里：锁眼好找好用，把手舒服，向下开门 技工： 眼中：详细结构+精密连接 心里：研究它的材质，连接方式 符合用户的心里： 就是把本来很复杂的事情设计成符合用户日常生活中常用的浏览方式或操作方式；也可以理解为人性化设计 比如银行转账，在转账时会有历史记录，确保让用户在第一次转账正确后放心转账 西克法则 定律内容：一个人面临的选择（n）越多，所需要作出决定的时间（T）就越长 7+-2法则：人们短期记忆每次能处理5—9件事情，作为把导航菜单的元素限制在7个以内的依据，因此根据产品需要，尽可能减少用户的选择项目数。 接近法则线框内的元素特征 军事，社会，国际是新闻的类型 股票，基金，外汇是财经领域的一部分 并排放置的频道，都是相近类型 微信网页版，MAC版，WIN版只是同一产品的不同类型 聊天输入时，可能用语音，图片，表情，红包等功能 放置在一起因为他们都是聊天可输入的内容 防错原则 注销的二次确认是防止用户点击错误 复制验证码是防止用户验证码输入错误 防错原则认为：大部分的意外都是由设计的疏忽，而不是人为操作的疏忽。通过改变设计可以把过失降到最低 操作可预期 看到线框内的元素我们会有所预期： 我会支付一笔钱 我会进入一个商铺首页 比如我们点击倒三角形，我们的预期是下拉出更多内容 贴近认知 在国内前两个图表辨识度极高，第三个图表在国内辨识度不高。所以对于国内网站，尽量不要使用第三个图标 比如看视频，当点击播放时，画面一下子横置，这样就超出了用户基本认知和预期，降低了使用流畅度 7 状态可感知当用户读完新闻之后，要把新闻列表中读过的新闻灰掉，让用户知道自己处于什么状态了再比如进度条，当前位置，数据加载等 一致性图中方框部分头像方圆不统一，再有列表头像是可以点击，但是订阅列表页不可点击。 总结 好的交互让使用产品的过程更愉悦 好的交互有基本的原则可以轻易遵循 4.2 交互设计核心和步骤交互设计的核心任务 表达 使用界面语言向用户传递信息，进而实现人机交互 交互设计三步骤 概括待表达的信息，清理需求点 信息排序，需求点按照一定规则进行分类 界面语言翻译，画交互。 案例做一个新闻资讯客户端的官网 概括信息，列举需求 内容：形态包括文章，视频，突击 频道：推荐，财经，娱乐。。。 功能入口：登录，下载app，查看详情 运营位：编辑推荐，广告 界面形式突出视频及图片 排序，需求分类 频道：推荐，财经，娱乐… 内容：形态包括文章，视频，突击 功能入口：登录，下载app，查看详情 运营位：编辑推荐，广告 突出图 界面表达画出原型图，如图所示： 案例某直播工具产品定位：只给有直播权限的用户用于直播基本功能：登录，选择节目发起直播（节目在后台已配置好）补充信息：由于每个节目一个单独的直播流，所以若未终止直播，这个节目还可以进去续播（既意外断开或误操作等情况均可续播）需求：有场景用户需要临时发起直播，为这个功能设计交互流程 概括信息，列举需求 用户可以选择节目发起直播 用户可以临时发起直播 选择节目发起直播需要查看节目列表 临时发起直播需要配置基本信息 意外退出后登陆还可以续播 排序 用户可以选择节目发起直播？用户还可以发起临时直播 选择节目发起直播需要产看节目列表？ 临时发起直播需要配置基本信息？ 意外退出后登录还可以续播？ 重新梳理用户流程，完成设计 用户登录后，主要操作发起直播，次要操作修改信息；查询记录 发起直播会遇到两种选择 根据不同选择走不同流程)) 虽然设计之后流程增加的步骤，但是产品体验性更好 总结 交互设计的过程需要对用户需求进行充分的了解 信息的展示与流程的设置必须遵循基本的原则 4.2 交互 在大公司会有专业UI我们需要做的： 写交互需求，包含需求背景的描述，需求目标的描述，需求点的列举，或低保真原型图 与交互设计师面对面沟通 及时督促交互稿完成 确认交互稿 在小公司需要做的： 需求分析 需求点分类 界面输出 根据需求大小选择不同输出方式 与leader沟通 产品经理的交互图： 重点是表述你需要啥功能及其优先级 美观需求次之 简单快捷的方式输出（手工，PS，画板均可） 各个端交互差异 区别 PC端 移动端 页面结构的差异 PC端在页面横向信息量比较大;PC端纵向页面层次信息比较深;PC端可以在新标签打开 移动端遵循少即是多原则，剔除不必要的元素，页面层次不要太深 操作方式不同 鼠标键盘，输入更容易，操作更便捷； 手指输入需要减少输入，降低输入难度；有更多便捷的输入方式（语音）；不要轻易打断用户任务（不好返回首页） 应用场景不同 固定场景，适合重度使用产品 碎片化事件，产品体验要更轻；更关注网络状态及流量使用 总结 交互知识是产品经理的必备技能 不追求技巧，把握方向 5 原型与需求文档5.1 原型 什么是原型原型是交互设计师与PD,PM,网站开发工程师沟通的最好工具。而该块的设计在原则上必须是交互设计师的产物，交互设计师以用户为中心的理念会贯穿整个产品。利用交互设计师专业的眼光与经验直接导致该产品的可用性。 原型的本质 原型的本质是工具 工具的本质是用于完成工作提高效率 原型的分类 高保真VS低保真 低保真：利用线框图，把信息的组织架构通过图形的模式展示。 高保真：利用高功能性，高互动性完整的把用户的操作流程表现出来 纵向原型设计VS横向原型设计 纵向：能通过点击交互到更深的层次 横向：以切面的形式展现页面跳转 部分特殊需求，如对体验效果特别看重，或功能及其复杂需要拟定较好的高保真demo一遍技术实现后的对比 原型的工具 Axure 墨刀 sketch Mockplus 原型的方法 分析需求 了解功能分布 明确页面层级 绘制基本原型 操作校验原型 5.2 原型案例 直播 案例背景：主播在直播过程中，有以下几种情况会推出直播 不方便，需要关闭画面（如补妆） 主动退出，直播结束 意外退出（网络中断） 结束后的功能 生成回顾，完成直播地址的使用 继续留在原地址直播 用户需求 在需要时不结束直播，仅暂停直播画面 意外状态下，能尽快重新连接直播地址 生成直播回顾 功能 画面中止 直播流终止 回顾视频生成 页面层级 第一层级：直播过程的界面 第二层级：直播结束的界面 第三层级：重新连接直播的界面 下面是两个原型，比较两个原型不难发现 是否退出尽量只有是和否 返回列表之前放的位置太过隐蔽 分享应该是下一层级做的事情，如果在这一层级不明确是分享正在直播的地址，还是分享我结束直播后的视频 提示可以让更多用户生成回顾 总结 原型是一个提高产品设计工作效率的工具 不同的需求使用不同要求的原型 5.3 需求文档PRD 重点描述一个新产品或现有产品改进的需求 核心：侧重的是对产品功能和性能等特性（即“产品需求”）的说明 作用： 指导开发 测试依据 后续存档 目标： 准确的描述需求，使得产品最终形态与预期温和 能够有效协助产品干系人（视觉，交互，页面，开发，测试）完成与预期吻合的产品 需求文档的结构 5.3 需求文档步骤 想需求 列特性 写初稿 补细节 想需求 不着急下笔，先想清楚需求 每份需求文档都是一个文字版的解决方案 想的内容： 项目核心需求是什么？ 解决用户的什么问题？ 主要功能逻辑有什么？ 回顾产品设计阶段的输出物 产品结构图 流程图 特性列表 列特性 理解需求后，列出解决方案中应包含的全部特性 特性点几个方面 功能特性 界面特性 性能要求 数据上报 写初稿根据上面的需求文档的结构图来写需求文档 需求背景及目标 需求背景作用 方便参与者了解需求 方便后续存档查阅 需求目标作用 写需求前再次审核需求 需求完成后校验需求 列特性列表 根据需求拆分特性点 拆分标准 按照内部逻辑（按照不同的功能模块，不同的页面进行拆分） 重要的部分单列特性 特性列表作用 明确需求模块 方便参与者理解需求并开发需求 主要逻辑 逻辑图灵活使用 复杂特性，流程图梳理逻辑 简单特性可以用文字描述 常用工具 Visio Edraw 逻辑图的作用 帮助梳理需求逻辑 减少细节遗漏 特性功能点 描述特性功能 流程细节描述 正常逻辑，异常逻辑 文案内容，性能需求（如发起操作后3S内有反馈） 交互图 特性功能描述的作用 开发测试最关键的依据 性能需求产品性能，实际上指的是产品的功能和质量两个方面在进行功能的需求撰写时，也需要关注产品本身的质量，如打开速度，崩溃率，并发能力，负载能力等 错误：这个应用跑得太慢，你能让他快起来吗？ 正确：系统内90%的业务操作必须在5秒内得到响应，系统必须支持100个并发用户 数据需求产品需求在完成时，都应该为最终的检验做好数据采集的工作标准为： 能验证本次任务目标的核心数据指标。 本次迭代中新增的主要功能的核心指标。 案例：需求的核心目标为提高用户留存率 统计存留率，对比上线前后数值 案例：本次更新的内容为金币商城，包含金币发放，兑换，商城物品展示，信息填写等功能 统计每日金币发放总量，用户量；兑换消耗金币量，用户量，兑换次数，不同物品兑换次数，按日统计 补细节 重读需求文档，补充未尽的细节 用挑剔的眼光看文档 检查需求描述，是否有歧义 检查用户场景是否全部覆盖到（主要看异常逻辑是否被覆盖） 假设自己是开发，能否用文档写出代码 5.4 好的需求文档好的需求文档： 能正确满足产品需求，逻辑清晰 所有需求及场景都应给出具体的解决方案描述 需求描述无歧义，易读 每个特性都有优先级 需求可验证 不给出无法验证的描述；需求可追踪 案例 用户登录（完备性） 示例： 非会员用户，点击登陆后提示，不可使用 会员用户，登陆后正常给出操作界面 存在问题： 非会员提示语是什么？ 会员登录是否会失败？ 失败场景有哪些？对应操作是什么？ 会员登录后，是否有其他应给出的提示？ 拖拽上传（无歧义） 示例： 用户拖拽上传 存在问题： 只能拖拽上传单个文件？ 用户拖拽到哪里？ 改正后： 用户拖拽文件or文件夹移动到QQ网盘主界面文件展示区（不包含功能操作区）空白处时，则自动将该文件or文件夹添加到上传列表中。 提示用户登录超时（可验证） 示例： 用户长时间登录不成功时，提示登录失败 存在问题： 长时间是多久 改正后： 用户在N秒内登录不成功时，提示登录失败。N请开发建议时长。 总结 需求文档时产品方案的进一步完善 需求文档及原型成为产品设计中最核心的一个过程 5.5 案例分析 需求背景及目标 背景： 参考会说话的tom猫，做一个会说话的X小狗 目标 流畅用户体验 实现基本互动玩法 第一版 存在问题 仅描述了过程，但不是真正的流程 相关角色无法根据需求准确实现 改进思路 想：需求给谁看？需求目标是什么？ 列：主要特性有哪些？用户主要操作及反馈是啥？ 写：启动逻辑图 补：根据逻辑图补充细节描述 修改后： 总结： 需求往往很简单 准确的表述需求并不简单 思考关键用户流程，设计合理信息流转路径 文档的细节是否完善，直接影响产品设计工作的后续进程 什么时候需要些需求文档 外包型项目：由于产品开发团队使用团队分离，为了更好地确保交付后没有疑义所有内容最好用文档形式保存 复杂的产品：逻辑功能复杂业务参与方式较多均建议使用文档形式展示需求 什么时候不需要需求文档 一句话需求（但也需要存档） 简单逻辑需求且公司有敏捷项目管理系统 6 产品研发过程管理6.1 项目管理及研发流程项目管理是管理学的一个分支学科，对项目管理的定义是：指在项目活动中运用专门的知识，技能，工具和方法，是项目能够在有限资源限定条件下，实现或超过设定的需求和期望的过程。 开发模式 瀑布开发 概念：最典型的预见性的方法，严格遵循预先计划的需求分析，设计，编码，集成，测试，维护的步骤顺序进行 常见：外包项目 迭代开发（每个版本都有预期） 概念：是一种与传统的瀑布式开发相反的软件开发过程，它弥补了传统开发方式中的一些弱点，具有更高的成功率和生产率 常见：互联网项目（微信需要迭代） 螺旋开发 概念：瀑布模块和快速原型模型结合起来，强调了其他模型所忽视的风险分析，特别适合于大型复杂的系统。“螺旋模型”刚开始规模很小，当项目被定义得更好，更稳定时，逐渐开展。 常见：火箭的研制 敏捷开发 概念：是一种从1990年开始逐渐引起广泛关注的一些新型软件开发方法，是一种应对快速变化的需求的一种软件开发能力 常见：互联网开发（先抢占市场） 常见开发模式对比 瀑布，迭代，螺旋开发都是一种软件开发的生命周期模型 敏捷开发是多种软件开发项目管理方法的集合 敏捷开发是一种防范，迭代开发是一种开发模型 敏捷开发 互联网项目多以敏捷开发为主。 敏捷开发的核心理念就是以简单有效的方式快速达成目标，并在这个过程中及时的响应外界的变化，做出迅速的调整。 适合小团队，技术产品磨合较好的团队 可以去文档，但要有存根 6.2 产品开发全流程管理项目主流程图 需求准备 需求分析 个人完成前期的分析初步的结论 需求讨论 小团队协助需求解决方案的PK及优化建议，是个人完成方案的优化及确认 交互讨论 交互协助或产品个人输出形成初步原型 需求评审 多角色参与需求的最终确认 需求评审会需求评审会是由产品经理介绍相应的产品功能背景以及初步的设计方案（交互稿），由大家针对现有的方案进行PK，直至讨论出统一的结果的过程。开会目标 明确项目目标 让大家都能初步了解方案的核心 通过会议讨论让大家对方案达到基本认可 会议要点 求同存异：不要驶入把观点植入到其他人的脑中（只要大家主要方向一致，不要在意细节） 放过细节：不纠结在细节中，学会妥协会后跟进（前端或者后端实现的问题不要再会上深入讨论） 人人参与：保证与会着都明确目标及方案 把握时间：控制会议时长提高效率（最好控制在1小时内，2小时会议可以拆分两次） 评审会内容 参与方：设计，后端，前端，运营 介绍背景：评审方案细节 目标：要做到什么程度 规划时间 怎么做：技术分工要讨论 为什么：讨论得最终方案 评审会黄金72小时 提前3天确定哪个版本，哪些人，在哪开会 提前2天发交互原型，需求文档 提前1天收集对评审问题并初步解答 会议控制 总分总的方式进行解说 时刻铭记目标 从特性列表到原型再到交互 细节解纷时及时跳出回归问题本质 部分不重要细节会后再定 结束前将重点问题再次确认 会议总结 及时输出会议纪要 待跟进讨论问题明确到责任人 督促各岗位人员给出时间评估 最终将优化后的文档及原型同步给大家 测试用例评审会 测试用例：示例 测试用例评审会意义：细化需求点，异常逻辑 没有测试用例怎么办： 需求文档尽可能完善 开发阶段 督促进度：确保发布时间，灵活使用站立晨会或日报 解决问题，确保产品与预期一致：讨论的结论及时同步测试 体验与测试 谁，什么时候体验：产品，功能实现了 谁，什么时候测试：测试，技术提测了 体验目标： 保障功能与预期一致 测试目标： 保障可用性 发布准备 产品层面 测试结果验收 客服手册 运营层面 发布渠道准备 用户通知 推广运营策略制定 产品验收 验收的目的 确保产品的基本功能与需求一致 确保产品能顺利发布 谁来验收？ 不同的公司流程会有不同的验收人 常见责任人，对应的产品经理 严格要求质量的项目，有专门的验收会 验收标准 可用性：是否与需求要求一致，用户可顺利完成操作 易用性：交互设计手否能否提高用户的使用率 验收方法 对比需求文档或测试用例进行操作 实际工作中，产品经理验收 产品经理不是bug发现者 测试与设计共同协助完成验收 客服手册 使用者：一切有可能需直接解答用户使用疑问的角色，如运营，客服 主要内容：产品基本情况，本次更新功能介绍，使用操作指南，可能的问题及统一答复 常用渠道 苹果应用商店 安卓：应用宝，360，百度，华为，小米 。。。 产品经理的渠道相关工作 渠道包管理，渠道包验证 渠道介绍文案，图片 关注渠道下载量，关注渠道评论，渠道引流效果评估 用户通知 那些需要发布用户通知 影响基础服务的需要发布 影响用户操作的需要发布 如何发用户通知（需要提前发） 弹窗 小黄条通知 运营推广 判定本次发布内容的重要程度 战略性发布：大范围推广，目标新老用户 功能性优化：老用户重点推广 小优化：简单告知 需要产品经理做什么 准备运营需要的设计图 提前申请广告位 与运营同事沟通外部渠道 内部渠道确认，用户群，合作产品入口，用户通知系统 运营预期管理 发布留守 在产品发布时，产品经理，技术，客服等相关岗位均需至少留守一小时 确保服务稳定 观察用户使用情况，及时作出反应 协助解答可能引起的客服诉讼 一般情况发布时间会选择下班前1-2小时 回滚 什么情况需要回滚 新功能不能正常使用 新功能的发布引起其他关键功能不能使用 Bug修复时间不可预期 用户投诉极其强烈 避免回滚 预期管理,预测到可能的影响面，是否可以承受 测试完整，功能测试及性能测试尽可能完善 技术实现方案尽可能不要耦合 汇报 项目需要，任何事都要有始有终 领导需要安全感 团队需要鼓励 检验目标，是否达成基本预期 存在感 组织影响力 汇报内容 过程总结：是否如期完成，是否顺利，时间评估是否准确等 结果总结：是否达成预期 资源使用情况总结：技术，设计，运营资源 数据总结： 用户量，使用量，收入，成本 效果总结：用户反馈，市场反馈 上线邮件 告知：什么？多长时间？做了什么？ 感谢：相关领导，技术，设计，测试等同事 总结：基本情况小结 跟进：告知后续跟进计划 数据汇报 汇报时间：3天，7天，第一个月 汇报方式：邮件 汇报内容：基本数据表现，与预期是否一致，数据波动原因，可以继续提高数据的运营措施。 筛选反馈 已知BUG问题：用心回复 已知需求问题：评估优先级，是否需要提高 未知BUG问题：立刻联系用户或重现，改进 未知需求问题：需求分析 反馈跟进 普通用户个别问题，若不重要暂时不规划，若与原规划一致，则自然解决 普通用户普遍问题，需认真评估优先级，资源限制导致无法完成可向上及时求助 特殊用户个人问题，区分需求或bug；需求，区分其真实诉求；bug，建议尽快修改 特殊用户普遍问题，需求，尽可能完成，bug，立刻修改。 特殊用户是要么影响你的资源，要么影响你的口碑，只要不是完无理的要求，我们需用积极的态度去服务特殊用户 7 风险及沟通管理7.1 风险管理风险管理是指如何在项目或者企业一个肯定有风险的环境里把风险可能造成的不良影响减至最低的管理过程 风险不能被预防，但我们也要朝着绝对避免发生而努力意义：完成既定目标 风险识别 风险评估 风险评价 风险管理 案例: 场景：某公司，产品经理在老板授意下开始启动X项目，简单沟通未经评审就开始技术投入。技术团队共计投入2年经验后台人员一个，3个月经验毕业生前段一个。预计7日完成项目。暂无完整测试人力投入，待项目完成后视其他项目进行而定测试。 风险识别： 方案论证不够 目标不明确 老板需求随时变更 前端技术能力风险 版本发布质量问题 风险评估： 方案论证不够 由于未评审，该风险较大 目标不明确 由于未评审，该风险较大 老板需求随时变更 根据老板性格判断 前端技术能力风险 看方案，看个人能力，有可能有风险 版本发布质量问题 看方案复杂程度，有可能有风险 风险管理： 方案论证不够 深刻理解需求并组织评审会 目标不明确 目标以邮件方式分别与老板及团队确认 老板需求随时变更 方案拟定后与老板再沟通，邮件确认基本目标 前端技术能力风险 及时报备技术领导监控过程 版本发布质量问题 调配测试到位以保证版本发布质量 7.2 风险管理方法 预期管理 合理的背景分析 理性的市场预估 风险提前预判 获得领导确认 案例：领导预期过高怎么办 判断领导预期的真实性 多问，尝试换角度去问 资源分析 让领导意识到资源不够 过程风险管理 合理工作评估量 项目节点 需求优先级 减少不重要需求 案例：要发生需求变更怎么沟通？ 明确原因？技术的，市场的,老板的，产品的 技术：积极减少不必要的需求 市场：反馈上级，获得支持后积极调整 老板：明确必要性，适度调整 产品：自我检讨，保障项目顺利进行 风险发生后管理 根据情况适当调整发布时间 及时与关键岗位沟通（老板，运营，运维） 及时复盘总结 案例 背景：自研开发周期长，外部产品已有现成功能约定指定时间完成，结果对方需求理解有误。不能如期完成。 调整：重新明确需求，与领导沟通，与对方沟通。 教训： 合作项目，做什么一定要明确，文档化。 外包项目前期沟通要仔细。 7.3 沟通技巧 沟通的目的 说明事物 表达情感 建立关系 进行企图 沟通工具 文件（需要存档的内容） 审批内容 评审内容 评审结论 需求定稿 聊天工具（不紧急阶段性内容） 聊天讨论 资料传输 咨询 破冰 电话（紧急沟通内容） 急需决策 紧急故障 就等不回 距离远说不清 面谈（复杂内容） 文字表达难 重要事件 距离很近 拉近关系 各个阶段沟通重点 需求阶段 明确需求目标 明确时间点，里程碑 明确产品方向 开发阶段 明确每日进展 明确开发难度 减少需求变更 多体验保证需求预期 发布阶段 运营支持沟通 数据反馈沟通 用户沟通 不同角色沟通 领导 问题： 领导一般会说把那个功能进度加快， 做一个XX产品，照着XX那样就行。 XXX老板反映说我们产品他用了几分钟就崩溃了你查一下 解决： 多问+你的理解+确认 凡是有交代，件件有着落，事事有回音 定期主动汇报，邮件，面谈，信息技术 问题 技术A:性格好，技术一般，从不挑剔需求，勤勤恳恳 技术B：火爆男，技术牛，怼你没商量 技术C：墨迹哥，任何细节都和你确认，不确认不开发 技术D：自认产品感一流，自信满满做需求。 解决 对技术A： 对技术B：对我们帮助最大，多多虚心交流请求 对技术C：把需求文档写仔细，减少他耽误我们时间 对技术D： 测试 问题 测试人员普遍性质，思维严密，谨慎，一般不多言 解决 邀请测试人员参加需求评审会 及时向测试人员同步需求 设计师 问题 这个配色多好看啊，你审美有问题吧，我改不了 我不觉得这个按钮小呀，那么大，而且我们老大都通过了 解决： 尊重 引导，控制 运营 问题（和运营的合作关系是双向的） 他给你提需求，但是经常被说需求不靠谱 给他提需求，但是可能做的结果不够好 解决： 共同的目标 方案把关,保持沟通 成果共享 合作需求方 问题： 他们可能是任何部门的同事 也可能是外部公司的需求方执行者 会占用你的资源或是需要你对结果负责 解决： 明确需求及目标 沟通结果要记录 预期管理 下级沟通 问题 可能是毕业生一无所知 可能是老油条深谙职场心机 更可能是在专业和管理都不如你的一个普通员工 解决 信息尽可能对称 帮助总结，监督进度 对事不对人 表扬在人前，批评在人后 建立有效的沟通机制 定期沟通机制 会议：例会，评审会，头脑风暴会，资源协调会 日报/周报/月报 邮件：上线汇报，数据反馈，会议纪要，活动分析等 非正式沟通 小范围聚餐 午餐时间聊天 团队磨合上要注意 尽可能统一判断的标准（如一切以用户价值为依据） 不要试图说服，而是找到中和点 充分理解没每个角色的内心真实想法 7.3 产品经理和项目经理|主要工作|工作背景|主要负责|目标|角色–|–|–|–|–|–|产品经理|想|复合人才|规划|结果|产品的爸爸项目经理|做|技术背景|实现|过程|产品的保姆 产品经理与项目经理如何合作 产品对实现细节负责 项目对实现过程负责 提前沟通提前规划 明确目标合理妥协 8 产品设计中的用户体验8.1用户体验1. 用户体验的五个层次用户体验是一种纯粹主观用户使用产品过程中建立起来的感受。 有用&gt;易用&gt;友好性&gt;视觉 战略层 关键词：产品目标，用户需求 企业用过产品获得什么 商业目标，品牌识别，成功标准 用户通过产品获得什么 目标用户，需求分析 范围层 关键词：功能，需求分析 确定产品功能的优先级 定义需求，需求清单，优先级 需求 文档描述 结构层 关键词：行为设计，流程图 交互设计：系统如何影响和相应用户的行为 用户行为设计，流程图 信息架构：如何有效组织信息 界面结构设计 框架层 关键词：界面设计，页面布局 界面设计 导航设计 信息设计 遵循用户日常使用习惯 前挡是用生活中的比喻 表现层 关键词：视觉传达 表现层，你能看到感受到的直观物体 基于感官体系的感知设计 视觉，界面，配色，图案 听觉，系统音 嗅觉，触觉，味觉 战略是一切要素的基础 2. 认知过程中的体验 认知包括 名称 市场分析，产品，行业，用户 符合自身核心方向 简单易传播 延展性强 Slogan 举例： 一席：人文，科技，白日梦 361：多一度热爱 类型： 独特卖点式：怕上火喝王老吉 传达感受式：纵享丝滑 鼓励行动式：携程在手，说走就走 怡情式：睡在山海间住进情人里 品牌性格式：自律给我自由 提炼方法 易传播发 压缩法 延展法 两套体系法 包装设计 是感官体验中最重要的一环，视觉体验 倡导新审美 水平思维法 观察法 保持精益，尽量简单 文本最小化 气质 拟人化 企业气质的影响 产品战略的影响 实用气质VS创新气质 男性气质VS女性气质 时机 技术成熟 社会发展 民众情绪 行业变化 提高用户对产品的第一印象 用户对于产品的第一印象极大地影响其用户的体验 第一印象可有多个因素构成 3. 使用过程中的体验 使用过程中的体验 交互 瀑布流（快手） 图片为主，无需精确操作，动态变化的信息 卡片式（携程） 程序时间，真实世界，与视觉世界三者完美结合 优点：约束信息布局，强调主体内容 注意的点：不要为了卡片而卡片，卡片拓展性较差，界面层级较多，若无谓的使用严重违背了极简设计 时间轴（天气） 优点：形式感强，清晰，细节丰富，华东体验连贯 注意的点：展现占用篇幅大，不适合快速提取关键信息。 技巧： 区分应用场景 根据产品类型 分析内容形态 注意时间因素 页面视觉 颜色的体验 扁平化 少特效，简单元素，注重排版，关注色彩，极简主义 无边框 掌控注意力，减少设计束缚，增加界面利用率，提升设计效率 功能设计原则 时刻把自己当做用户 用操作流程开表达设计方案 在每一个关键点进行多场景分析 文案 目标 保障可用性 提高易用性 4. 服务过程中的体验 服务过程中的体验包括 客服 反馈 运营活动 目标 提高用户忠诚度 客服渠道 用户异步获取信息渠道 内部反馈渠道，邮件，论坛，微博私信，公众号 用户主动查询信息渠道 FAQ，帮助 用户实时沟通信息渠道 在线客服，电话客服 如何帮助提高客服效率 产品设计用户体验角度出发 主动发现用户问题 提供客服手册 及时回复反馈 让用户感受到被关注 有利于塑造正面形象 团队内客户导向观念的建立 提高反馈回复的质量 感谢用户，肯定对产品的贡献 不轻易道歉 根据用户的反馈给与适当的回复 运营活动如何平衡用户体验和企业需求 保障用户的基本需求被满足 可以欺骗但要美好 总结 服务的体验是影响用户留存的重要因素 根据用户基本诉求及时给与解决方案 8.2 用户体验地图从用户角度出发，以叙述故事的方式描述用户与公司相关产品之间的互动，并以可视化图形将其展示，这一过程的产出物即为用户体验地图。 用户体验地图是一种工具 帮助大家从用户角度考虑产品，设计产品 优势 好看 情感化设计 多人参与 基本元素 用户角色 谁 需求 期望 痛点 时间线 时间单位（周/月） 行为划分（浏览，收藏，购买） 情绪指数 情感变化 关键节点 关键动作 使用场景 在哪里","categories":[{"name":"产品文档","slug":"产品文档","permalink":"http://zhuangyea.github.io/categories/产品文档/"}],"tags":[{"name":"产品","slug":"产品","permalink":"http://zhuangyea.github.io/tags/产品/"}]}]}